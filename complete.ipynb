{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> __________________Sepehr Rezaei__________________ \n",
    "<h3> ________________________rsepehr746@gmail.com________________________ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6   ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8  spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  \n",
       "5        NaN        NaN  \n",
       "6        NaN        NaN  \n",
       "7        NaN        NaN  \n",
       "8        NaN        NaN  \n",
       "9        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=pd.read_csv( 'spam.csv',encoding='ISO-8859-1')\n",
    "text.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.drop(['Unnamed: 2', 'Unnamed: 3','Unnamed: 4'], axis=1,inplace=True)\n",
    "# Verify the updated DataFrame\n",
    "text.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>number of ham & spam sms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['v1'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>change ham to 0 and spam to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro...\n",
       "5   1  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   0  Even my brother is not like to speak with me. ...\n",
       "7   0  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8   1  WINNER!! As a valued network customer you have...\n",
       "9   1  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['v1'] = text['v1'].replace({'ham': 0, 'spam': 1})\n",
    "text.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Pre_Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>make words to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>as per your request 'melle melle (oru minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>winner!! as a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>had your mobile 11 months or more? u r entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  go until jurong point, crazy.. available only ...\n",
       "1   0                      ok lar... joking wif u oni...\n",
       "2   1  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3   0  u dun say so early hor... u c already then say...\n",
       "4   0  nah i don't think he goes to usf, he lives aro...\n",
       "5   1  freemsg hey there darling it's been 3 week's n...\n",
       "6   0  even my brother is not like to speak with me. ...\n",
       "7   0  as per your request 'melle melle (oru minnamin...\n",
       "8   1  winner!! as a valued network customer you have...\n",
       "9   1  had your mobile 11 months or more? u r entitle..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['v2']=text['v2'].str.lower()\n",
    "text.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point, crazy.. available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say early hor... u c already say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah think goes usf, lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg hey darling 3 week's word back! i'd li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>even brother like speak me. treat like aids pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>per request 'melle melle (oru minnaminunginte ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>winner!! valued network customer selected rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>mobile 11 months more? u r entitled update lat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  go jurong point, crazy.. available bugis n gre...\n",
       "1   0                      ok lar... joking wif u oni...\n",
       "2   1  free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3   0          u dun say early hor... u c already say...\n",
       "4   0            nah think goes usf, lives around though\n",
       "5   1  freemsg hey darling 3 week's word back! i'd li...\n",
       "6   0  even brother like speak me. treat like aids pa...\n",
       "7   0  per request 'melle melle (oru minnaminunginte ...\n",
       "8   1  winner!! valued network customer selected rece...\n",
       "9   1  mobile 11 months more? u r entitled update lat..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword=set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word.lower() not in stopword]\n",
    "    return ' '.join(words)\n",
    "# Apply the remove_stopwords function to the 'sms' column\n",
    "text['v2'] = text['v2'].apply(remove_stopwords)\n",
    "text.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Stemming with Porter stemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import porter\n",
    "Pstemmer = porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point, crazy.. available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say early hor... u c already say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah think goes usf, lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg hey darling 3 week's word back! i'd li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>even brother like speak me. treat like aids pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>per request 'melle melle (oru minnaminunginte ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>winner!! valued network customer selected rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>mobile 11 months more? u r entitled update lat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  go jurong point, crazy.. available bugis n gre...\n",
       "1   0                      ok lar... joking wif u oni...\n",
       "2   1  free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3   0          u dun say early hor... u c already say...\n",
       "4   0            nah think goes usf, lives around though\n",
       "5   1  freemsg hey darling 3 week's word back! i'd li...\n",
       "6   0  even brother like speak me. treat like aids pa...\n",
       "7   0  per request 'melle melle (oru minnaminunginte ...\n",
       "8   1  winner!! valued network customer selected rece...\n",
       "9   1  mobile 11 months more? u r entitled update lat..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['v2'] = [Pstemmer.stem(word=wo) for wo in text['v2']]\n",
    "text.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tokenization-TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x8820 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 50149 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFFi=TfidfVectorizer()\n",
    "tffi_tokenized_text=TFFi.fit_transform(text['v2'])\n",
    "tffi_tokenized_text\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Bag of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow_model = vectorizer.fit_transform(text['v2'])\n",
    "bow_tokenized_text=bow_model.toarray()      # returns the rows and column number of cells which have 1 as value\n",
    "print(bow_tokenized_text)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Split data to Train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tffi_x_train,tffi_x_test,tffi_y_train,tffi_y_test=train_test_split(tffi_tokenized_text,text['v1'],random_state=42,shuffle=True,test_size=0.3,stratify=text['v1'])\n",
    "bow_x_train,bow_x_test,bow_y_train,bow_y_test=train_test_split(bow_tokenized_text,text['v1'],random_state=42,shuffle=True,test_size=0.3,stratify=text['v1'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score,accuracy_score,precision_score,f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9479665071770335"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tffi_knn=KNeighborsClassifier(n_neighbors=13)\n",
    "tffi_knn.fit(tffi_x_train,tffi_y_train)\n",
    "knn_tffi_pred=tffi_knn.predict(X=tffi_x_test)\n",
    "tffi_knn.score(X=tffi_x_test,y=tffi_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8773923444976076"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_knn=KNeighborsClassifier(n_neighbors=13)\n",
    "bow_knn.fit(X=bow_x_train,y=bow_y_train)\n",
    "knn_bow_pred=bow_knn.predict(X=bow_x_test)\n",
    "bow_knn.score(X=bow_x_test,y=bow_y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Measurin knn algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring knn wit TF*IDF :\n",
      "\n",
      "Accuracy: 0.9479665071770335\n",
      "Recall: 0.6116071428571429\n",
      "Precision: 1.0\n",
      "F1-score: 0.7590027700831026\n",
      "\n",
      "\n",
      "Measuring knn wit BOW :\n",
      "\n",
      "Accuracy: 0.8773923444976076\n",
      "Recall: 0.08482142857142858\n",
      "Precision: 1.0\n",
      "F1-score: 0.15637860082304528\n"
     ]
    }
   ],
   "source": [
    "knn_tffi_precision = precision_score(tffi_y_test, knn_tffi_pred)\n",
    "knn_tffi_recall = recall_score(tffi_y_test, knn_tffi_pred)\n",
    "knn_tffi_f1 = f1_score(tffi_y_test, knn_tffi_pred)\n",
    "knn_tffi_accuracy = accuracy_score(tffi_y_test, knn_tffi_pred)\n",
    "print(\"Measuring knn wit TF*IDF :\\n\")\n",
    "print(\"Accuracy:\", knn_tffi_accuracy)\n",
    "print(\"Recall:\", knn_tffi_recall)\n",
    "print(\"Precision:\", knn_tffi_precision)\n",
    "print(\"F1-score:\", knn_tffi_f1)\n",
    "\n",
    "knn_bow_precision = precision_score(bow_y_test, knn_bow_pred)\n",
    "knn_bow_recall = recall_score(bow_y_test, knn_bow_pred)\n",
    "knn_bow_f1 = f1_score(bow_y_test, knn_bow_pred)\n",
    "knn_bow_accuracy = accuracy_score(bow_y_test, knn_bow_pred)\n",
    "print(\"\\n\\nMeasuring knn wit BOW :\\n\")\n",
    "print(\"Accuracy:\", knn_bow_accuracy)\n",
    "print(\"Recall:\", knn_bow_recall)\n",
    "print(\"Precision:\", knn_bow_precision)\n",
    "print(\"F1-score:\", knn_bow_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp=0\n",
    "for index, item in enumerate(bow_y_test):\n",
    "    if item == 1 and knn_bow_pred[index]==1:\n",
    "        tp+=1\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp=0\n",
    "for index, item in enumerate(bow_y_test):\n",
    "    if item == 1 and knn_bow_pred[index]==0:\n",
    "        fp+=1\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn=0\n",
    "for index, item in enumerate(bow_y_test):\n",
    "    if item == 0 and knn_bow_pred[index]==1:\n",
    "        fn+=1\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1448"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn=0\n",
    "for index, item in enumerate(bow_y_test):\n",
    "    if item == 0 and knn_bow_pred[index]==0:\n",
    "        tn+=1\n",
    "tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15637860082304528"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1=(2*tp)/(2*tp+fp+fn)\n",
    "f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08482142857142858"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precion=tp/(tp+fp)\n",
    "precion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall=tp/(tp+fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8773923444976076"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=(tp+tn)/1672\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Random forest with TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9730861244019139"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tffi_Random_F=RandomForestClassifier(n_estimators=31,criterion='gini')\n",
    "tffi_Random_F.fit(tffi_x_train,tffi_y_train)\n",
    "tffi_Randmon_F_pred=tffi_Random_F.predict(X=tffi_x_test)\n",
    "tffi_Random_F.score(X=tffi_x_test,y=tffi_y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Random_forest with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9754784688995215"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_Random_F=RandomForestClassifier(n_estimators=31,criterion='gini')\n",
    "bow_Random_F.fit(bow_x_train,bow_y_train)\n",
    "bow_Randmon_F_pred=bow_Random_F.predict(X=bow_x_test)\n",
    "bow_Random_F.score(X=bow_x_test,y=bow_y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Measuring both Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring Random forest wit TF*IDF :\n",
      "\n",
      "Accuracy: 0.9730861244019139\n",
      "Recall: 0.8035714285714286\n",
      "Precision: 0.994475138121547\n",
      "F1-score: 0.888888888888889\n",
      "\n",
      "\n",
      "Measuring Random forest wit BOW :\n",
      "\n",
      "Accuracy: 0.9754784688995215\n",
      "Recall: 0.8169642857142857\n",
      "Precision: 1.0\n",
      "F1-score: 0.8992628992628993\n"
     ]
    }
   ],
   "source": [
    "tffi_Random_F_precision = precision_score(tffi_y_test, tffi_Randmon_F_pred)\n",
    "tffi_Random_F_recall = recall_score(tffi_y_test, tffi_Randmon_F_pred)\n",
    "tffi_Random_F_f1 = f1_score(tffi_y_test, tffi_Randmon_F_pred)\n",
    "tffi_Random_F_accuracy = accuracy_score(tffi_y_test, tffi_Randmon_F_pred)\n",
    "print(\"Measuring Random forest wit TF*IDF :\\n\")\n",
    "print(\"Accuracy:\", tffi_Random_F_accuracy)\n",
    "print(\"Recall:\", tffi_Random_F_recall)\n",
    "print(\"Precision:\", tffi_Random_F_precision)\n",
    "print(\"F1-score:\", tffi_Random_F_f1)\n",
    "\n",
    "bow_Random_F_precision = precision_score(bow_y_test, bow_Randmon_F_pred)\n",
    "bow_Random_F_recall = recall_score(bow_y_test, bow_Randmon_F_pred)\n",
    "bow_Random_F_f1 = f1_score(bow_y_test, bow_Randmon_F_pred)\n",
    "bow_Random_F_accuracy = accuracy_score(bow_y_test, bow_Randmon_F_pred)\n",
    "print(\"\\n\\nMeasuring Random forest wit BOW :\\n\")\n",
    "print(\"Accuracy:\", bow_Random_F_accuracy)\n",
    "print(\"Recall:\", bow_Random_F_recall)\n",
    "print(\"Precision:\", bow_Random_F_precision)\n",
    "print(\"F1-score:\", bow_Random_F_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>SVM with TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9838516746411483"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tffi_SVM=svm.SVC(kernel='rbf',C=10,gamma=0.1)\n",
    "tffi_SVM.fit(tffi_x_train,tffi_y_train)\n",
    "tffi_SVM_pred=tffi_SVM.predict(X=tffi_x_test)\n",
    "tffi_SVM.score(X=tffi_x_test,y=tffi_y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>SVM with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9784688995215312"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_SVM=svm.SVC(kernel='rbf',C=10,gamma=0.1)\n",
    "bow_SVM.fit(bow_x_train,bow_y_train)\n",
    "bow_SVM_pred=bow_SVM.predict(X=bow_x_test)\n",
    "bow_SVM.score(X=bow_x_test,y=bow_y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Measuring SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring SVM wit TF*IDF :\n",
      "\n",
      "Accuracy: 0.9838516746411483\n",
      "Recall: 0.8928571428571429\n",
      "Precision: 0.9852216748768473\n",
      "F1-score: 0.936768149882904\n",
      "\n",
      "\n",
      "Measuring SVM wit BOW :\n",
      "\n",
      "Accuracy: 0.9784688995215312\n",
      "Recall: 0.8392857142857143\n",
      "Precision: 1.0\n",
      "F1-score: 0.9126213592233009\n"
     ]
    }
   ],
   "source": [
    "tffi_SVM_precision = precision_score(tffi_y_test, tffi_SVM_pred)\n",
    "tffi_SVM_recall = recall_score(tffi_y_test, tffi_SVM_pred)\n",
    "tffi_SVM_f1 = f1_score(tffi_y_test, tffi_SVM_pred)\n",
    "tffi_SVM_accuracy = accuracy_score(tffi_y_test, tffi_SVM_pred)\n",
    "print(\"Measuring SVM wit TF*IDF :\\n\")\n",
    "print(\"Accuracy:\", tffi_SVM_accuracy)\n",
    "print(\"Recall:\", tffi_SVM_recall)\n",
    "print(\"Precision:\", tffi_SVM_precision)\n",
    "print(\"F1-score:\", tffi_SVM_f1)\n",
    "\n",
    "bow_SVM_precision = precision_score(bow_y_test, bow_SVM_pred)\n",
    "bow_SVM_recall = recall_score(bow_y_test, bow_SVM_pred)\n",
    "bow_SVM_f1 = f1_score(bow_y_test, bow_SVM_pred)\n",
    "bow_SVM_accuracy = accuracy_score(bow_y_test, bow_SVM_pred)\n",
    "print(\"\\n\\nMeasuring SVM wit BOW :\\n\")\n",
    "print(\"Accuracy:\", bow_SVM_accuracy)\n",
    "print(\"Recall:\", bow_SVM_recall)\n",
    "print(\"Precision:\", bow_SVM_precision)\n",
    "print(\"F1-score:\", bow_SVM_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Learning MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import  keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>split TF*IDF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_tf_x_train_full, mlp_tf_x_test, mlp_tf_y_train_full, mlp_tf_y_test = train_test_split(tffi_tokenized_text.toarray(),text['v1'],random_state=42,shuffle=True,test_size=0.1,stratify=text['v1'])\n",
    "mlp_tf_x_train,mlp_tf_x_valid, mlp_tf_y_train, mlp_tf_y_valid = train_test_split(mlp_tf_x_train_full, mlp_tf_y_train_full,test_size=0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>split BOW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_bow_x_train_full, mlp_bow_x_test, mlp_bow_y_train_full, mlp_bow_y_test = train_test_split(bow_tokenized_text,text['v1'],random_state=42,shuffle=True,test_size=0.1,stratify=text['v1'])\n",
    "mlp_bow_x_train,mlp_bow_x_valid, mlp_bow_y_train, mlp_bow_y_valid = train_test_split(mlp_bow_x_train_full, mlp_bow_y_train_full,test_size=0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>MLP with TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import  keras\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(200, activation='relu', input_shape=(mlp_tf_x_train.shape[1],)))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3267 - accuracy: 0.9005 - val_loss: 0.1062 - val_accuracy: 0.9781\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0563 - accuracy: 0.9867 - val_loss: 0.0584 - val_accuracy: 0.9861\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0197 - accuracy: 0.9965 - val_loss: 0.0508 - val_accuracy: 0.9861\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9984 - val_loss: 0.0495 - val_accuracy: 0.9861\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.0494 - val_accuracy: 0.9880\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9880\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9880\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9880\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9880\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 8.8080e-04 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9880\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0936 - accuracy: 0.9767\n",
      "Test loss: 0.093551866710186\n",
      "Test accuracy: 0.9767025113105774\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(mlp_tf_x_train, mlp_tf_y_train, validation_data=(mlp_tf_x_valid, mlp_tf_y_valid), epochs=10, batch_size=32)\n",
    "# Evaluate the model\n",
    "score1 = model1.evaluate(mlp_tf_x_test, mlp_tf_y_test)\n",
    "print('Test loss:', score1[0])\n",
    "print('Test accuracy:', score1[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>evaluate model on trainig data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 7.3641e-04 - accuracy: 1.0000\n",
      "Train Loss: 0.0007364078774116933\n",
      "Train Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the train set\n",
    "train_loss1, train_accuracy1 = model1.evaluate(mlp_tf_x_train, mlp_tf_y_train)\n",
    "print(\"Train Loss:\", train_loss1)\n",
    "print(\"Train Accuracy:\", train_accuracy1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.9767025089605734\n",
      "Recall: 0.8266666666666667\n",
      "Precision: 1.0\n",
      "F1-score: 0.9051094890510949\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob1 = model1.predict(mlp_tf_x_test)\n",
    "\n",
    "# Converting probabilities to class labels based on a threshold \n",
    "y_pred1 = (y_pred_prob1 >= 0.5).astype(int)\n",
    "\n",
    "# Calculating precision, recall, F1-score, and accuracy\n",
    "precision1 = precision_score(mlp_tf_y_test, y_pred1)\n",
    "recall1 = recall_score(mlp_tf_y_test, y_pred1)\n",
    "f11 = f1_score(mlp_tf_y_test, y_pred1)\n",
    "accuracy1 = accuracy_score(mlp_tf_y_test, y_pred1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy1)\n",
    "print(\"Recall:\", recall1)\n",
    "print(\"Precision:\", precision1)\n",
    "print(\"F1-score:\", f11)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MLP with BOW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(200, activation='relu', input_shape=(mlp_bow_x_train.shape[1],)))\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model with SCA optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2283 - accuracy: 0.9546 - val_loss: 0.0592 - val_accuracy: 0.9920\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0283 - accuracy: 0.9947 - val_loss: 0.0351 - val_accuracy: 0.9940\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.0312 - val_accuracy: 0.9920\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.0310 - val_accuracy: 0.9920\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.0315 - val_accuracy: 0.9920\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0322 - val_accuracy: 0.9920\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0329 - val_accuracy: 0.9920\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0337 - val_accuracy: 0.9920\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 8.9561e-04 - accuracy: 0.9998 - val_loss: 0.0342 - val_accuracy: 0.9920\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 7.3889e-04 - accuracy: 0.9998 - val_loss: 0.0351 - val_accuracy: 0.9940\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9803\n",
      "Test loss: 0.10615494102239609\n",
      "Test accuracy: 0.980286717414856\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(mlp_bow_x_train, mlp_bow_y_train, validation_data=(mlp_bow_x_valid, mlp_bow_y_valid), epochs=10, batch_size=32)\n",
    "# Evaluate the model\n",
    "score2 = model2.evaluate(mlp_bow_x_test, mlp_bow_y_test)\n",
    "print('Test loss:', score2[0])\n",
    "print('Test accuracy:', score2[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>evaluate model on trainig data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/141 [..............................] - ETA: 2s - loss: 2.7501e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step - loss: 6.0036e-04 - accuracy: 0.9998\n",
      "Train Loss: 0.000600355735514313\n",
      "Train Accuracy: 0.9997783899307251\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the train set\n",
    "train_loss2, train_accuracy2 = model2.evaluate(mlp_bow_x_train, mlp_bow_y_train)\n",
    "print(\"Train Loss:\", train_loss2)\n",
    "print(\"Train Accuracy:\", train_accuracy2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.9802867383512545\n",
      "Recall: 0.8533333333333334\n",
      "Precision: 1.0\n",
      "F1-score: 0.9208633093525179\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob2 = model2.predict(mlp_bow_x_test)\n",
    "\n",
    "# Converting probabilities to class labels based on a threshold \n",
    "y_pred2 = (y_pred_prob2 >= 0.5).astype(int)\n",
    "\n",
    "# Calculating precision, recall, F1-score, and accuracy\n",
    "precision2 = precision_score(mlp_bow_y_test, y_pred2)\n",
    "recall2 = recall_score(mlp_bow_y_test, y_pred2)\n",
    "f12 = f1_score(mlp_bow_y_test, y_pred2)\n",
    "accuracy2 = accuracy_score(mlp_bow_y_test, y_pred2)\n",
    "\n",
    "print(\"Accuracy:\", accuracy2)\n",
    "print(\"Recall:\", recall2)\n",
    "print(\"Precision:\", precision2)\n",
    "print(\"F1-score:\", f12)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>MLP with scaled data  TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scailing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "mlp_tf_x_train_scaled = scaler.fit_transform(mlp_tf_x_train)\n",
    "mlp_tf_x_valid_scaled = scaler.transform(mlp_tf_x_valid)\n",
    "mlp_tf_x_test_scaled = scaler.transform(mlp_tf_x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(200, activation='relu', input_shape=(mlp_tf_x_train_scaled.shape[1],)))\n",
    "model3.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 6ms/step - loss: 2.5821 - accuracy: 0.8127 - val_loss: 0.4706 - val_accuracy: 0.9502\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0781 - accuracy: 0.9885 - val_loss: 0.1951 - val_accuracy: 0.9661\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.1635 - val_accuracy: 0.9661\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.1509 - val_accuracy: 0.9681\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9701\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9701\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 4.7201e-04 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9701\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.7686e-04 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9701\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.9463e-04 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9701\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.4800e-04 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9701\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9713\n",
      "Test Loss: 0.1753864288330078\n",
      "Test Accuracy: 0.9713261723518372\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(mlp_tf_x_train_scaled, mlp_tf_y_train, validation_data=(mlp_tf_x_valid_scaled, mlp_tf_y_valid), epochs=10, batch_size=32)\n",
    "test_loss3, test_accuracy3 = model3.evaluate(mlp_tf_x_test_scaled, mlp_tf_y_test)\n",
    "print(\"Test Loss:\", test_loss3)\n",
    "print(\"Test Accuracy:\", test_accuracy3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.9713261648745519\n",
      "Recall: 0.7866666666666666\n",
      "Precision: 1.0\n",
      "F1-score: 0.8805970149253731\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob3 = model3.predict(mlp_tf_x_test_scaled)\n",
    "\n",
    "# Converting probabilities to class labels based on a threshold \n",
    "y_pred3 = (y_pred_prob3 >= 0.5).astype(int)\n",
    "\n",
    "# Calculating precision, recall, F1-score, and accuracy\n",
    "precision3 = precision_score(mlp_tf_y_test, y_pred3)\n",
    "recall3 = recall_score(mlp_tf_y_test, y_pred3)\n",
    "f13 = f1_score(mlp_tf_y_test, y_pred3)\n",
    "accuracy3 = accuracy_score(mlp_tf_y_test, y_pred3)\n",
    "\n",
    "print(\"Accuracy:\", accuracy3)\n",
    "print(\"Recall:\", recall3)\n",
    "print(\"Precision:\", precision3)\n",
    "print(\"F1-score:\", f13)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feature Selection with SCA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sca import SCAFUN    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>We have to scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2=StandardScaler()\n",
    "scaled_data=scaler2.fit_transform(tffi_tokenized_text.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8820)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_obj_data=scaled_data.astype(float)\n",
    "scaled_obj_label=text['v1'].astype(float)\n",
    "scaled_obj_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>First extract TFIDF feature vectors with SCA on scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_train_SCA, scaled_x_valid_SCA, scaled_y_train_SCA, scaled_y_valid_SCA = train_test_split(scaled_obj_data, scaled_obj_label, test_size=0.2, stratify=scaled_obj_label,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = {'x_train':scaled_x_train_SCA, 'y_train':scaled_y_train_SCA, 'x_valid':scaled_x_valid_SCA, 'y_valid':scaled_y_valid_SCA}\n",
    "T    = 5   # maximum number of iterations\n",
    "opts = {'fold':fold, 'T':T,'alpha':0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCA_knn = SCAFUN(scaled_obj_data, scaled_obj_label, opts,'knn')\n",
    "sf_knn   = SCA_knn['selected_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = {'x_train':scaled_x_train_SCA, 'y_train':scaled_y_train_SCA, 'x_valid':scaled_x_valid_SCA, 'y_valid':scaled_y_valid_SCA}\n",
    "T    = 5   # maximum number of iterations\n",
    "opts = {'fold':fold, 'T':T,'alpha':0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 2ms/step - loss: 0.7299\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1211\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1451\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1177\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0227\n",
      "35/35 [==============================] - 0s 982us/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.8900\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.5657\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.4465\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0604\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0290\n",
      "35/35 [==============================] - 0s 949us/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.8064\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1741\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0299\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0228\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.2142\n",
      "35/35 [==============================] - 0s 912us/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 1.0351\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1861\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0291\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.2070\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.9782\n",
      "35/35 [==============================] - 0s 952us/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.8708\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.5644\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.5536\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1396\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0325\n",
      "35/35 [==============================] - 0s 935us/step\n"
     ]
    }
   ],
   "source": [
    "SCA_output1 = SCAFUN(scaled_obj_data, scaled_obj_label, opts,'mlp')\n",
    "sf1   = SCA_output1['selected_features']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Size of selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4412"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf1.size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>So  8820-4391=4429 features were omitted by applying  SCA "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>splite extracted scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca_x_train,mlp_sca_x_test,sca_y_train,mlp_sca_y_test=train_test_split(scaled_obj_data[:,sf1],scaled_obj_label,test_size=0.3,stratify=scaled_obj_label,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_sca_x_train,mlp_sca_x_valid, mlp_sca_y_train, mlp_sca_y_valid = train_test_split(sca_x_train, sca_y_train,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Now extract BOW feature vectors with SCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8820)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_obj_data=bow_tokenized_text.astype(float)\n",
    "bow_obj_label=text['v1'].astype(float)\n",
    "bow_obj_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_x_train, bow_x_valid, bow_y_train, bow_y_valid = train_test_split(bow_obj_data, bow_obj_label, test_size=0.2, stratify=bow_obj_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = {'x_train':bow_x_train, 'y_train':bow_y_train, 'x_valid':bow_x_valid, 'y_valid':bow_y_valid}\n",
    "T    = 5   # maximum number of iterations\n",
    "opts = {'fold':fold, 'T':T,'alpha':0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 3ms/step - loss: 0.1307\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0218\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0040\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 4ms/step - loss: 5.0879e-04\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 3ms/step - loss: 0.1347\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0040\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0010\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 4.1379e-04\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 3ms/step - loss: 0.1350\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0045\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0020\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 3ms/step - loss: 0.1366\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0187\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0066\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "35/35 [==============================] - 0s 990us/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 2ms/step - loss: 0.1353\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0198\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0054\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0023\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "35/35 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "SCA_output2 = SCAFUN(bow_obj_data, bow_obj_label, opts,'mlp')\n",
    "sf2   = SCA_output2['selected_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4436,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf2.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>So  8820-4462=4358 features were omitted by applying  SCA "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>load extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca_x_bow_train,mlp_sca_x_bow_test,sca_y_bow_train,mlp_sca_y_bow_test=train_test_split(bow_obj_data[:,sf2],bow_obj_label,test_size=0.3,stratify=bow_obj_label,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_sca_bow_x_train,mlp_sca_bow_x_valid, mlp_sca_bow_y_train, mlp_sca_bow_y_valid = train_test_split(sca_x_bow_train, sca_y_bow_train,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KNN with SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8702153110047847"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCA_tffi_knn=KNeighborsClassifier(n_neighbors=13)\n",
    "SCA_tffi_knn.fit(sca_x_train,sca_y_train)\n",
    "SCA_knn_tffi_pred=SCA_tffi_knn.predict(X=mlp_sca_x_test)\n",
    "SCA_tffi_knn.score(X=mlp_sca_x_test,y=mlp_sca_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.881578947368421"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCA_bow_knn=KNeighborsClassifier(n_neighbors=13)\n",
    "SCA_bow_knn.fit(X=sca_x_bow_train,y=sca_y_bow_train)\n",
    "SCA_knn_bow_pred=SCA_bow_knn.predict(X=mlp_sca_x_bow_test)\n",
    "SCA_bow_knn.score(X=mlp_sca_x_bow_test,y=mlp_sca_y_bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring knn wit TF*IDF SCA:\n",
      "\n",
      "Accuracy: 0.8702153110047847\n",
      "Recall: 0.03125\n",
      "Precision: 1.0\n",
      "F1-score: 0.06060606060606061\n",
      "\n",
      "\n",
      "Measuring knn wit BOW SCA :\n",
      "\n",
      "Accuracy: 0.881578947368421\n",
      "Recall: 0.11607142857142858\n",
      "Precision: 1.0\n",
      "F1-score: 0.208\n"
     ]
    }
   ],
   "source": [
    "SCA_knn_tffi_precision = precision_score(mlp_sca_y_test, SCA_knn_tffi_pred)\n",
    "SCA_knn_tffi_recall = recall_score(mlp_sca_y_test, SCA_knn_tffi_pred)\n",
    "SCA_knn_tffi_f1 = f1_score(mlp_sca_y_test, SCA_knn_tffi_pred)\n",
    "SCA_knn_tffi_accuracy = accuracy_score(mlp_sca_y_test, SCA_knn_tffi_pred)\n",
    "print(\"Measuring knn wit TF*IDF SCA:\\n\")\n",
    "print(\"Accuracy:\", SCA_knn_tffi_accuracy)\n",
    "print(\"Recall:\", SCA_knn_tffi_recall)\n",
    "print(\"Precision:\", SCA_knn_tffi_precision)\n",
    "print(\"F1-score:\", SCA_knn_tffi_f1)\n",
    "\n",
    "SCA_knn_bow_precision = precision_score(mlp_sca_y_bow_test, SCA_knn_bow_pred)\n",
    "SCA_knn_bow_recall = recall_score(mlp_sca_y_bow_test, SCA_knn_bow_pred)\n",
    "SCA_knn_bow_f1 = f1_score(mlp_sca_y_bow_test, SCA_knn_bow_pred)\n",
    "SCA_knn_bow_accuracy = accuracy_score(mlp_sca_y_bow_test, SCA_knn_bow_pred)\n",
    "print(\"\\n\\nMeasuring knn wit BOW SCA :\\n\")\n",
    "print(\"Accuracy:\", SCA_knn_bow_accuracy)\n",
    "print(\"Recall:\", SCA_knn_bow_recall)\n",
    "print(\"Precision:\", SCA_knn_bow_precision)\n",
    "print(\"F1-score:\", SCA_knn_bow_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_SCA=0\n",
    "for index, item in enumerate(mlp_sca_y_bow_test):\n",
    "    if item == 1 and SCA_knn_bow_pred[index]==1:\n",
    "        tp_SCA+=1\n",
    "tp_SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_SCA=0\n",
    "for index, item in enumerate(mlp_sca_y_bow_test):\n",
    "    if item == 1 and SCA_knn_bow_pred[index]==0:\n",
    "        fp_SCA+=1\n",
    "fp_SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_SCA=0\n",
    "for index, item in enumerate(mlp_sca_y_bow_test):\n",
    "    if item == 0 and SCA_knn_bow_pred[index]==1:\n",
    "        fn_SCA+=1\n",
    "fn_SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1448"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn_SCA=0\n",
    "for index, item in enumerate(mlp_sca_y_bow_test):\n",
    "    if item == 0 and SCA_knn_bow_pred[index]==0:\n",
    "        tn_SCA+=1\n",
    "tn_SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.208"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_SCA=(2*tp_SCA)/(2*tp_SCA+fp_SCA+fn_SCA)\n",
    "f1_SCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11607142857142858"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precion_SCA=tp_SCA/(tp_SCA+fp_SCA)\n",
    "precion_SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_SCA=tp_SCA/(tp_SCA+fn_SCA)\n",
    "recall_SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.881578947368421"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_SCA=(tp_SCA+tn_SCA)/1672\n",
    "accuracy_SCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random forest with SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9712918660287081"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCA_tffi_Random_F=RandomForestClassifier(n_estimators=31,criterion='gini')\n",
    "SCA_tffi_Random_F.fit(sca_x_train,sca_y_train)\n",
    "SCA_tffi_Randmon_F_pred=SCA_tffi_Random_F.predict(X=mlp_sca_x_test)\n",
    "SCA_tffi_Random_F.score(X=mlp_sca_x_test,y=mlp_sca_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9694976076555024"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCA_bow_Random_F=RandomForestClassifier(n_estimators=31,criterion='gini')\n",
    "SCA_bow_Random_F.fit(sca_x_bow_train,sca_y_bow_train)\n",
    "SCA_bow_Randmon_F_pred=SCA_bow_Random_F.predict(X=mlp_sca_x_bow_test)\n",
    "SCA_bow_Random_F.score(X=mlp_sca_x_bow_test,y=mlp_sca_y_bow_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>measuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring Random forest wit TF*IDF :\n",
      "\n",
      "Accuracy: 0.9712918660287081\n",
      "Recall: 0.8392857142857143\n",
      "Precision: 0.94\n",
      "F1-score: 0.8867924528301886\n",
      "\n",
      "\n",
      "Measuring Random forest wit BOW :\n",
      "\n",
      "Accuracy: 0.9694976076555024\n",
      "Recall: 0.8080357142857143\n",
      "Precision: 0.9576719576719577\n",
      "F1-score: 0.8765133171912832\n"
     ]
    }
   ],
   "source": [
    "SCA_tffi_Random_F_precision = precision_score(mlp_sca_y_test, SCA_tffi_Randmon_F_pred)\n",
    "SCA_tffi_Random_F_recall = recall_score(mlp_sca_y_test, SCA_tffi_Randmon_F_pred)\n",
    "SCA_tffi_Random_F_f1 = f1_score(mlp_sca_y_test, SCA_tffi_Randmon_F_pred)\n",
    "SCA_tffi_Random_F_accuracy = accuracy_score(mlp_sca_y_test, SCA_tffi_Randmon_F_pred)\n",
    "print(\"Measuring Random forest wit TF*IDF :\\n\")\n",
    "print(\"Accuracy:\", SCA_tffi_Random_F_accuracy)\n",
    "print(\"Recall:\", SCA_tffi_Random_F_recall)\n",
    "print(\"Precision:\", SCA_tffi_Random_F_precision)\n",
    "print(\"F1-score:\", SCA_tffi_Random_F_f1)\n",
    "\n",
    "SCA_bow_Random_F_precision = precision_score(mlp_sca_y_bow_test, SCA_bow_Randmon_F_pred)\n",
    "SCA_bow_Random_F_recall = recall_score(mlp_sca_y_bow_test, SCA_bow_Randmon_F_pred)\n",
    "SCA_bow_Random_F_f1 = f1_score(mlp_sca_y_bow_test, SCA_bow_Randmon_F_pred)\n",
    "SCA_bow_Random_F_accuracy = accuracy_score(mlp_sca_y_bow_test, SCA_bow_Randmon_F_pred)\n",
    "print(\"\\n\\nMeasuring Random forest wit BOW :\\n\")\n",
    "print(\"Accuracy:\", SCA_bow_Random_F_accuracy)\n",
    "print(\"Recall:\", SCA_bow_Random_F_recall)\n",
    "print(\"Precision:\", SCA_bow_Random_F_precision)\n",
    "print(\"F1-score:\", SCA_bow_Random_F_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SCA SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9007177033492823"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCA_tffi_SVM=svm.SVC(kernel='rbf',C=10,gamma=0.1)\n",
    "SCA_tffi_SVM.fit(sca_x_train,sca_y_train)\n",
    "SCA_tffi_SVM_pred=SCA_tffi_SVM.predict(X=mlp_sca_x_test)\n",
    "SCA_tffi_SVM.score(X=mlp_sca_x_test,y=mlp_sca_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9748803827751196"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCA_bow_SVM=svm.SVC(kernel='rbf',C=10,gamma=0.1)\n",
    "SCA_bow_SVM.fit(sca_x_bow_train,sca_y_bow_train)\n",
    "SCA_bow_SVM_pred=SCA_bow_SVM.predict(X=mlp_sca_x_bow_test)\n",
    "SCA_bow_SVM.score(X=mlp_sca_x_bow_test,y=mlp_sca_y_bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring SVM wit TF*IDF :\n",
      "\n",
      "Accuracy: 0.9007177033492823\n",
      "Recall: 0.26339285714285715\n",
      "Precision: 0.9833333333333333\n",
      "F1-score: 0.4154929577464789\n",
      "\n",
      "\n",
      "Measuring SVM wit BOW :\n",
      "\n",
      "Accuracy: 0.9748803827751196\n",
      "Recall: 0.8303571428571429\n",
      "Precision: 0.9789473684210527\n",
      "F1-score: 0.8985507246376812\n"
     ]
    }
   ],
   "source": [
    "SCA_tffi_SVM_precision = precision_score(mlp_sca_y_test, SCA_tffi_SVM_pred)\n",
    "SCA_tffi_SVM_recall = recall_score(mlp_sca_y_test, SCA_tffi_SVM_pred)\n",
    "SCA_tffi_SVM_f1 = f1_score(mlp_sca_y_test, SCA_tffi_SVM_pred)\n",
    "SCA_tffi_SVM_accuracy = accuracy_score(mlp_sca_y_test, SCA_tffi_SVM_pred)\n",
    "print(\"Measuring SVM wit TF*IDF :\\n\")\n",
    "print(\"Accuracy:\", SCA_tffi_SVM_accuracy)\n",
    "print(\"Recall:\", SCA_tffi_SVM_recall)\n",
    "print(\"Precision:\", SCA_tffi_SVM_precision)\n",
    "print(\"F1-score:\", SCA_tffi_SVM_f1)\n",
    "\n",
    "SCA_bow_SVM_precision = precision_score(mlp_sca_y_bow_test, SCA_bow_SVM_pred)\n",
    "SCA_bow_SVM_recall = recall_score(mlp_sca_y_bow_test, SCA_bow_SVM_pred)\n",
    "SCA_bow_SVM_f1 = f1_score(mlp_sca_y_bow_test, SCA_bow_SVM_pred)\n",
    "SCA_bow_SVM_accuracy = accuracy_score(mlp_sca_y_bow_test, SCA_bow_SVM_pred)\n",
    "print(\"\\n\\nMeasuring SVM wit BOW :\\n\")\n",
    "print(\"Accuracy:\", SCA_bow_SVM_accuracy)\n",
    "print(\"Recall:\", SCA_bow_SVM_recall)\n",
    "print(\"Precision:\", SCA_bow_SVM_precision)\n",
    "print(\"F1-score:\", SCA_bow_SVM_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Make mlp with SCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 1s 4ms/step - loss: 2.7764 - accuracy: 0.7551 - val_loss: 1.0672 - val_accuracy: 0.8397\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9644 - val_loss: 0.2243 - val_accuracy: 0.9372\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9904 - val_loss: 0.1664 - val_accuracy: 0.9577\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.1516 - val_accuracy: 0.9615\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9946 - val_loss: 0.1370 - val_accuracy: 0.9667\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.1391 - val_accuracy: 0.9654\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.1366 - val_accuracy: 0.9692\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.1399 - val_accuracy: 0.9705\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.1465 - val_accuracy: 0.9679\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.1411 - val_accuracy: 0.9692\n",
      "53/53 [==============================] - 0s 972us/step - loss: 0.1343 - accuracy: 0.9659\n",
      "Test loss: 0.1342526525259018\n",
      "Test accuracy: 0.9659090638160706\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(200, activation='relu', input_shape=(mlp_sca_x_train.shape[1],)))\n",
    "model5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model \n",
    "model5.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Training the model\n",
    "history5 = model5.fit(mlp_sca_x_train, mlp_sca_y_train, validation_data=(mlp_sca_x_valid, mlp_sca_y_valid), epochs=10, batch_size=32)\n",
    "# Evaluate the model\n",
    "score5 = model5.evaluate(mlp_sca_x_test, mlp_sca_y_test)\n",
    "print('Test loss:', score5[0])\n",
    "print('Test accuracy:', score5[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>evalute model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "Accuracy: 0.9659090909090909\n",
      "Recall: 0.84375\n",
      "Precision: 0.8957345971563981\n",
      "F1-score: 0.8689655172413794\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob5 = model5.predict(mlp_sca_x_test)\n",
    "\n",
    "# Converting probabilities to class labels based on a threshold (e.g., 0.5)\n",
    "y_pred5 = (y_pred_prob5 >= 0.5).astype(int)\n",
    "\n",
    "# Calculating precision, recall, F1-score, and accuracy\n",
    "precision5 = precision_score(mlp_sca_y_test, y_pred5)\n",
    "recall5 = recall_score(mlp_sca_y_test, y_pred5)\n",
    "f15 = f1_score(mlp_sca_y_test, y_pred5)\n",
    "accuracy5 = accuracy_score(mlp_sca_y_test, y_pred5)\n",
    "\n",
    "print(\"Accuracy:\", accuracy5)\n",
    "print(\"Recall:\", recall5)\n",
    "print(\"Precision:\", precision5)\n",
    "print(\"F1-score:\", f15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>make mlp _ SCA on BOW data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 1s 4ms/step - loss: 0.3764 - accuracy: 0.9029 - val_loss: 0.1521 - val_accuracy: 0.9705\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0956 - accuracy: 0.9776 - val_loss: 0.0821 - val_accuracy: 0.9859\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9875 - val_loss: 0.0719 - val_accuracy: 0.9885\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9929 - val_loss: 0.0707 - val_accuracy: 0.9885\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0712 - val_accuracy: 0.9885\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.0721 - val_accuracy: 0.9885\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.0728 - val_accuracy: 0.9885\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.0747 - val_accuracy: 0.9885\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.0764 - val_accuracy: 0.9885\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0781 - val_accuracy: 0.9885\n",
      "53/53 [==============================] - 0s 961us/step - loss: 0.0745 - accuracy: 0.9749\n",
      "Test loss: 0.07447601854801178\n",
      "Test accuracy: 0.9748803973197937\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(200, activation='relu', input_shape=(mlp_sca_bow_x_train.shape[1],)))\n",
    "model6.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with SCA optimizer\n",
    "model6.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Training the model\n",
    "history6 = model6.fit(mlp_sca_bow_x_train, mlp_sca_bow_y_train, validation_data=(mlp_sca_bow_x_valid, mlp_sca_bow_y_valid), epochs=10, batch_size=32)\n",
    "# Evaluate the model\n",
    "score6 = model6.evaluate(mlp_sca_x_bow_test, mlp_sca_y_bow_test)\n",
    "print('Test loss:', score6[0])\n",
    "print('Test accuracy:', score6[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 0.9997\n",
      "Train Loss: 0.003629501909017563\n",
      "Train Accuracy: 0.9996795058250427\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loss6, train_accuracy6 = model6.evaluate(mlp_sca_bow_x_train, mlp_sca_bow_y_train)\n",
    "print(\"Train Loss:\", train_loss6)\n",
    "print(\"Train Accuracy:\", train_accuracy6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 923us/step\n",
      "Accuracy: 0.9748803827751196\n",
      "Recall: 0.8258928571428571\n",
      "Precision: 0.9840425531914894\n",
      "F1-score: 0.8980582524271844\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob6 = model6.predict(mlp_sca_x_bow_test)\n",
    "\n",
    "# Converting probabilities to class labels based on a threshold (e.g., 0.5)\n",
    "y_pred6 = (y_pred_prob6 >= 0.5).astype(int)\n",
    "\n",
    "# Calculating precision, recall, F1-score, and accuracy\n",
    "precision6 = precision_score(mlp_sca_y_bow_test, y_pred6)\n",
    "recall6 = recall_score(mlp_sca_y_bow_test, y_pred6)\n",
    "f16 = f1_score(mlp_sca_y_bow_test, y_pred6)\n",
    "accuracy6 = accuracy_score(mlp_sca_y_bow_test, y_pred6)\n",
    "\n",
    "print(\"Accuracy:\", accuracy6)\n",
    "print(\"Recall:\", recall6)\n",
    "print(\"Precision:\", precision6)\n",
    "print(\"F1-score:\", f16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>make result Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy      BOW</th>\n",
       "      <th>Accuracy   TF-IDF</th>\n",
       "      <th>Precision     BOW</th>\n",
       "      <th>Precision  TF-IDF</th>\n",
       "      <th>Recall        BOW</th>\n",
       "      <th>Recall     TF-IDF</th>\n",
       "      <th>F-measure     BOW</th>\n",
       "      <th>F-measure  TF-IDF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>98.028674</td>\n",
       "      <td>97.670251</td>\n",
       "      <td>85.333333</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>92.086331</td>\n",
       "      <td>92.086331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-scaled</th>\n",
       "      <td>----------</td>\n",
       "      <td>97.132616</td>\n",
       "      <td>----------</td>\n",
       "      <td>78.666667</td>\n",
       "      <td>----------</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>----------</td>\n",
       "      <td>88.059701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-SCA</th>\n",
       "      <td>97.488038</td>\n",
       "      <td>96.590909</td>\n",
       "      <td>82.589286</td>\n",
       "      <td>84.375000</td>\n",
       "      <td>98.404255</td>\n",
       "      <td>89.573460</td>\n",
       "      <td>89.805825</td>\n",
       "      <td>86.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>87.739234</td>\n",
       "      <td>94.796651</td>\n",
       "      <td>8.482143</td>\n",
       "      <td>61.160714</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>15.63786</td>\n",
       "      <td>75.900277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN-SCA</th>\n",
       "      <td>88.157895</td>\n",
       "      <td>87.021531</td>\n",
       "      <td>11.607143</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.8</td>\n",
       "      <td>6.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>97.84689</td>\n",
       "      <td>98.385167</td>\n",
       "      <td>83.928571</td>\n",
       "      <td>89.285714</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.522167</td>\n",
       "      <td>91.262136</td>\n",
       "      <td>93.676815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM-SCA</th>\n",
       "      <td>97.488038</td>\n",
       "      <td>90.071770</td>\n",
       "      <td>83.035714</td>\n",
       "      <td>26.339286</td>\n",
       "      <td>97.894737</td>\n",
       "      <td>98.333333</td>\n",
       "      <td>89.855072</td>\n",
       "      <td>41.549296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R.forest</th>\n",
       "      <td>97.368421</td>\n",
       "      <td>97.607656</td>\n",
       "      <td>80.357143</td>\n",
       "      <td>83.482143</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.421053</td>\n",
       "      <td>89.108911</td>\n",
       "      <td>90.338164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R.forest-SCA</th>\n",
       "      <td>96.949761</td>\n",
       "      <td>97.129187</td>\n",
       "      <td>80.803571</td>\n",
       "      <td>83.928571</td>\n",
       "      <td>95.767196</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>87.651332</td>\n",
       "      <td>88.679245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy      BOW  Accuracy   TF-IDF Precision     BOW  \\\n",
       "Algorithm                                                             \n",
       "MLP                  98.028674          97.670251         85.333333   \n",
       "MLP-scaled          ----------          97.132616        ----------   \n",
       "MLP-SCA              97.488038          96.590909         82.589286   \n",
       "KNN                  87.739234          94.796651          8.482143   \n",
       "KNN-SCA              88.157895          87.021531         11.607143   \n",
       "SVM                   97.84689          98.385167         83.928571   \n",
       "SVM-SCA              97.488038          90.071770         83.035714   \n",
       "R.forest             97.368421          97.607656         80.357143   \n",
       "R.forest-SCA         96.949761          97.129187         80.803571   \n",
       "\n",
       "              Precision  TF-IDF Recall        BOW  Recall     TF-IDF  \\\n",
       "Algorithm                                                              \n",
       "MLP                   82.666667             100.0         100.000000   \n",
       "MLP-scaled            78.666667        ----------         100.000000   \n",
       "MLP-SCA               84.375000         98.404255          89.573460   \n",
       "KNN                   61.160714             100.0         100.000000   \n",
       "KNN-SCA                3.125000             100.0         100.000000   \n",
       "SVM                   89.285714             100.0          98.522167   \n",
       "SVM-SCA               26.339286         97.894737          98.333333   \n",
       "R.forest              83.482143             100.0          98.421053   \n",
       "R.forest-SCA          83.928571         95.767196          94.000000   \n",
       "\n",
       "             F-measure     BOW  F-measure  TF-IDF  \n",
       "Algorithm                                          \n",
       "MLP                  92.086331          92.086331  \n",
       "MLP-scaled          ----------          88.059701  \n",
       "MLP-SCA              89.805825          86.896552  \n",
       "KNN                   15.63786          75.900277  \n",
       "KNN-SCA                   20.8           6.060606  \n",
       "SVM                  91.262136          93.676815  \n",
       "SVM-SCA              89.855072          41.549296  \n",
       "R.forest             89.108911          90.338164  \n",
       "R.forest-SCA         87.651332          88.679245  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mlp_12 = {'Algorithm': 'MLP', 'Accuracy_BOW': accuracy2*100 ,'Accuracy_TF-IDF':accuracy1*100 , 'Recall_BOW': recall2*100, 'Recall_TF-IDF': recall1*100,'Precision_BOW':precision2*100  ,'Precision_TF-IDF':precision1*100 ,'F-measure_BOW':f12*100,'F-measure_TF-IDF':f12*100}\n",
    "results_mlp3 = {'Algorithm': 'MLP-scaled', 'Accuracy_BOW': '----------' ,'Accuracy_TF-IDF':accuracy3*100 , 'Recall_BOW': '----------', 'Recall_TF-IDF': recall3*100,'Precision_BOW':'----------'  ,'Precision_TF-IDF':precision3*100 ,'F-measure_BOW':'----------','F-measure_TF-IDF':f13*100}\n",
    "results_mlp_56 = {'Algorithm': 'MLP-SCA', 'Accuracy_BOW': accuracy6*100 ,'Accuracy_TF-IDF':accuracy5*100 , 'Recall_BOW': recall6*100, 'Recall_TF-IDF': recall5*100,'Precision_BOW':precision6*100  ,'Precision_TF-IDF':precision5*100 ,'F-measure_BOW':f16*100,'F-measure_TF-IDF':f15*100}\n",
    "results_knn = {'Algorithm': 'KNN', 'Accuracy_BOW': knn_bow_accuracy*100 ,'Accuracy_TF-IDF':knn_tffi_accuracy*100 , 'Recall_BOW': knn_bow_recall*100, 'Recall_TF-IDF': knn_tffi_recall*100,'Precision_BOW':knn_bow_precision*100  ,'Precision_TF-IDF':knn_tffi_precision*100 ,'F-measure_BOW':knn_bow_f1*100,'F-measure_TF-IDF':knn_tffi_f1*100}\n",
    "results_svm = {'Algorithm': 'SVM', 'Accuracy_BOW': bow_SVM_accuracy*100 ,'Accuracy_TF-IDF':tffi_SVM_accuracy*100 , 'Recall_BOW': bow_SVM_recall*100, 'Recall_TF-IDF': tffi_SVM_recall*100,'Precision_BOW':bow_SVM_precision*100  ,'Precision_TF-IDF':tffi_SVM_precision*100 ,'F-measure_BOW':bow_SVM_f1*100,'F-measure_TF-IDF':tffi_SVM_f1*100}\n",
    "results_rf = {'Algorithm': 'R.forest', 'Accuracy_BOW': bow_Random_F_accuracy*100 ,'Accuracy_TF-IDF':tffi_Random_F_accuracy*100 , 'Recall_BOW': bow_Random_F_recall*100, 'Recall_TF-IDF': tffi_Random_F_recall*100,'Precision_BOW':bow_Random_F_precision*100  ,'Precision_TF-IDF':tffi_Random_F_precision*100 ,'F-measure_BOW':bow_Random_F_f1*100,'F-measure_TF-IDF':tffi_Random_F_f1*100}\n",
    "\n",
    "\n",
    "\n",
    "results_SCA_knn = {'Algorithm': 'KNN-SCA', 'Accuracy_BOW': SCA_knn_bow_accuracy*100 ,'Accuracy_TF-IDF':SCA_knn_tffi_accuracy*100 , 'Recall_BOW': SCA_knn_bow_recall*100, 'Recall_TF-IDF': SCA_knn_tffi_recall*100,'Precision_BOW':SCA_knn_bow_precision*100  ,'Precision_TF-IDF':SCA_knn_tffi_precision*100 ,'F-measure_BOW':SCA_knn_bow_f1*100,'F-measure_TF-IDF':SCA_knn_tffi_f1*100}\n",
    "results_SCA_svm = {'Algorithm': 'SVM-SCA', 'Accuracy_BOW': SCA_bow_SVM_accuracy*100 ,'Accuracy_TF-IDF':SCA_tffi_SVM_accuracy*100 , 'Recall_BOW': SCA_bow_SVM_recall*100, 'Recall_TF-IDF': SCA_tffi_SVM_recall*100,'Precision_BOW':SCA_bow_SVM_precision*100  ,'Precision_TF-IDF':SCA_tffi_SVM_precision*100 ,'F-measure_BOW':SCA_bow_SVM_f1*100,'F-measure_TF-IDF':SCA_tffi_SVM_f1*100}\n",
    "results_SCA_rf = {'Algorithm': 'R.forest-SCA', 'Accuracy_BOW': SCA_bow_Random_F_accuracy*100 ,'Accuracy_TF-IDF':SCA_tffi_Random_F_accuracy*100 , 'Recall_BOW': SCA_bow_Random_F_recall*100, 'Recall_TF-IDF': SCA_tffi_Random_F_recall*100,'Precision_BOW':SCA_bow_Random_F_precision*100  ,'Precision_TF-IDF':SCA_tffi_Random_F_precision*100 ,'F-measure_BOW':SCA_bow_Random_F_f1*100,'F-measure_TF-IDF':SCA_tffi_Random_F_f1*100}\n",
    "df = pd.DataFrame([results_mlp_12, results_mlp3,results_mlp_56,results_knn,results_SCA_knn,results_svm,results_SCA_svm,results_rf,results_SCA_rf])\n",
    "df.set_index('Algorithm', inplace=True)\n",
    "columns = pd.MultiIndex.from_tuples([\n",
    "    ('Accuracy', 'BOW'), ('Accuracy', 'TF-IDF'),\n",
    "    ('Precision', 'BOW'), ('Precision', 'TF-IDF'),\n",
    "    ('Recall', 'BOW'), ('Recall', 'TF-IDF'),\n",
    "    ('F-measure', 'BOW'), ('F-measure', 'TF-IDF')\n",
    "])\n",
    "\n",
    "df.columns = columns\n",
    "\n",
    "# Define column spacing\n",
    "col_width = max(len(name) for name in df.columns.get_level_values(0))\n",
    "level_width = max(len(str(level)) for level in df.columns.get_level_values(1))\n",
    "spacing = 2  # Number of extra spaces between columns\n",
    "\n",
    "# Function to format column headers with adjusted spacing\n",
    "def format_columns(columns):\n",
    "    return [f\"{col:{col_width}s}{level:>{level_width + spacing}s}\" for col, level in columns]\n",
    "\n",
    "# Format columns with adjusted spacing\n",
    "df.columns = format_columns(df.columns)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Save  result table as chart.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([results_mlp_12, results_mlp3,results_mlp_56,results_knn,results_SCA_knn,results_svm,results_SCA_svm,results_rf,results_SCA_rf])\n",
    "df.set_index('Algorithm', inplace=True)\n",
    "df.to_csv('chart_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
