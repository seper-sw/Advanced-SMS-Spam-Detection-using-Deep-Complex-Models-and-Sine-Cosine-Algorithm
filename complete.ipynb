{
 "cells": [
   {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> _____________Sepehr Rezaei_____________ ",
    "<h3> ______rsepehr746@gmail.com______ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6   ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8  spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  \n",
       "5        NaN        NaN  \n",
       "6        NaN        NaN  \n",
       "7        NaN        NaN  \n",
       "8        NaN        NaN  \n",
       "9        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=pd.read_csv( 'spam.csv',encoding='ISO-8859-1')\n",
    "text.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.drop(['Unnamed: 2', 'Unnamed: 3','Unnamed: 4'], axis=1,inplace=True)\n",
    "# Verify the updated DataFrame\n",
    "text.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>number of ham & spam sms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['v1'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>change ham to 0 and spam to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro...\n",
       "5   1  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   0  Even my brother is not like to speak with me. ...\n",
       "7   0  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8   1  WINNER!! As a valued network customer you have...\n",
       "9   1  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['v1'] = text['v1'].replace({'ham': 0, 'spam': 1})\n",
    "text.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Pre_Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>make words to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>as per your request 'melle melle (oru minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>winner!! as a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>had your mobile 11 months or more? u r entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  go until jurong point, crazy.. available only ...\n",
       "1   0                      ok lar... joking wif u oni...\n",
       "2   1  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3   0  u dun say so early hor... u c already then say...\n",
       "4   0  nah i don't think he goes to usf, he lives aro...\n",
       "5   1  freemsg hey there darling it's been 3 week's n...\n",
       "6   0  even my brother is not like to speak with me. ...\n",
       "7   0  as per your request 'melle melle (oru minnamin...\n",
       "8   1  winner!! as a valued network customer you have...\n",
       "9   1  had your mobile 11 months or more? u r entitle..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['v2']=text['v2'].str.lower()\n",
    "text.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point, crazy.. available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say early hor... u c already say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah think goes usf, lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg hey darling 3 week's word back! i'd li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>even brother like speak me. treat like aids pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>per request 'melle melle (oru minnaminunginte ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>winner!! valued network customer selected rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>mobile 11 months more? u r entitled update lat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  go jurong point, crazy.. available bugis n gre...\n",
       "1   0                      ok lar... joking wif u oni...\n",
       "2   1  free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3   0          u dun say early hor... u c already say...\n",
       "4   0            nah think goes usf, lives around though\n",
       "5   1  freemsg hey darling 3 week's word back! i'd li...\n",
       "6   0  even brother like speak me. treat like aids pa...\n",
       "7   0  per request 'melle melle (oru minnaminunginte ...\n",
       "8   1  winner!! valued network customer selected rece...\n",
       "9   1  mobile 11 months more? u r entitled update lat..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword=set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word.lower() not in stopword]\n",
    "    return ' '.join(words)\n",
    "# Apply the remove_stopwords function to the 'sms' column\n",
    "text['v2'] = text['v2'].apply(remove_stopwords)\n",
    "text.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Stemming with Porter stemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import porter\n",
    "Pstemmer = porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point, crazy.. available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say early hor... u c already say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah think goes usf, lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg hey darling 3 week's word back! i'd li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>even brother like speak me. treat like aids pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>per request 'melle melle (oru minnaminunginte ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>winner!! valued network customer selected rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>mobile 11 months more? u r entitled update lat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  go jurong point, crazy.. available bugis n gre...\n",
       "1   0                      ok lar... joking wif u oni...\n",
       "2   1  free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3   0          u dun say early hor... u c already say...\n",
       "4   0            nah think goes usf, lives around though\n",
       "5   1  freemsg hey darling 3 week's word back! i'd li...\n",
       "6   0  even brother like speak me. treat like aids pa...\n",
       "7   0  per request 'melle melle (oru minnaminunginte ...\n",
       "8   1  winner!! valued network customer selected rece...\n",
       "9   1  mobile 11 months more? u r entitled update lat..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['v2'] = [Pstemmer.stem(word=wo) for wo in text['v2']]\n",
    "text.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tokenization-TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x8820 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 50149 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFFi=TfidfVectorizer()\n",
    "tffi_tokenized_text=TFFi.fit_transform(text['v2'])\n",
    "tffi_tokenized_text\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Bag of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow_model = vectorizer.fit_transform(text['v2'])\n",
    "bow_tokenized_text=bow_model.toarray()      # returns the rows and column number of cells which have 1 as value\n",
    "print(bow_tokenized_text)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Split data to Train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tffi_x_train,tffi_x_test,tffi_y_train,tffi_y_test=train_test_split(tffi_tokenized_text,text['v1'],random_state=42,shuffle=True,test_size=0.3,stratify=text['v1'])\n",
    "bow_x_train,bow_x_test,bow_y_train,bow_y_test=train_test_split(bow_tokenized_text,text['v1'],random_state=42,shuffle=True,test_size=0.3,stratify=text['v1'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score,accuracy_score,precision_score,f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9479665071770335"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tffi_knn=KNeighborsClassifier(n_neighbors=13)\n",
    "tffi_knn.fit(tffi_x_train,tffi_y_train)\n",
    "knn_tffi_pred=tffi_knn.predict(X=tffi_x_test)\n",
    "tffi_knn.score(X=tffi_x_test,y=tffi_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8773923444976076"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_knn=KNeighborsClassifier(n_neighbors=13)\n",
    "bow_knn.fit(X=bow_x_train,y=bow_y_train)\n",
    "knn_bow_pred=bow_knn.predict(X=bow_x_test)\n",
    "bow_knn.score(X=bow_x_test,y=bow_y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Measurin knn algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring knn wit TF*IDF :\n",
      "\n",
      "Accuracy: 0.9479665071770335\n",
      "Recall: 0.6116071428571429\n",
      "Precision: 1.0\n",
      "F1-score: 0.7590027700831026\n",
      "\n",
      "\n",
      "Measuring knn wit BOW :\n",
      "\n",
      "Accuracy: 0.8773923444976076\n",
      "Recall: 0.08482142857142858\n",
      "Precision: 1.0\n",
      "F1-score: 0.15637860082304528\n"
     ]
    }
   ],
   "source": [
    "knn_tffi_precision = precision_score(tffi_y_test, knn_tffi_pred)\n",
    "knn_tffi_recall = recall_score(tffi_y_test, knn_tffi_pred)\n",
    "knn_tffi_f1 = f1_score(tffi_y_test, knn_tffi_pred)\n",
    "knn_tffi_accuracy = accuracy_score(tffi_y_test, knn_tffi_pred)\n",
    "print(\"Measuring knn wit TF*IDF :\\n\")\n",
    "print(\"Accuracy:\", knn_tffi_accuracy)\n",
    "print(\"Recall:\", knn_tffi_recall)\n",
    "print(\"Precision:\", knn_tffi_precision)\n",
    "print(\"F1-score:\", knn_tffi_f1)\n",
    "\n",
    "knn_bow_precision = precision_score(bow_y_test, knn_bow_pred)\n",
    "knn_bow_recall = recall_score(bow_y_test, knn_bow_pred)\n",
    "knn_bow_f1 = f1_score(bow_y_test, knn_bow_pred)\n",
    "knn_bow_accuracy = accuracy_score(bow_y_test, knn_bow_pred)\n",
    "print(\"\\n\\nMeasuring knn wit BOW :\\n\")\n",
    "print(\"Accuracy:\", knn_bow_accuracy)\n",
    "print(\"Recall:\", knn_bow_recall)\n",
    "print(\"Precision:\", knn_bow_precision)\n",
    "print(\"F1-score:\", knn_bow_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Random forest with TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tffi_Random_F=RandomForestClassifier(n_estimators=31,criterion='gini')\n",
    "tffi_Random_F.fit(tffi_x_train,tffi_y_train)\n",
    "tffi_Randmon_F_pred=tffi_Random_F.predict(X=tffi_x_test)\n",
    "tffi_Random_F.score(X=tffi_x_test,y=tffi_y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Random_forest with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9754784688995215"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_Random_F=RandomForestClassifier(n_estimators=31,criterion='gini')\n",
    "bow_Random_F.fit(bow_x_train,bow_y_train)\n",
    "bow_Randmon_F_pred=bow_Random_F.predict(X=bow_x_test)\n",
    "bow_Random_F.score(X=bow_x_test,y=bow_y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Measuring both Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring Random forest wit TF*IDF :\n",
      "\n",
      "Accuracy: 0.9736842105263158\n",
      "Recall: 0.8169642857142857\n",
      "Precision: 0.9838709677419355\n",
      "F1-score: 0.8926829268292684\n",
      "\n",
      "\n",
      "Measuring Random forest wit BOW :\n",
      "\n",
      "Accuracy: 0.9754784688995215\n",
      "Recall: 0.8169642857142857\n",
      "Precision: 1.0\n",
      "F1-score: 0.8992628992628993\n"
     ]
    }
   ],
   "source": [
    "tffi_Random_F_precision = precision_score(tffi_y_test, tffi_Randmon_F_pred)\n",
    "tffi_Random_F_recall = recall_score(tffi_y_test, tffi_Randmon_F_pred)\n",
    "tffi_Random_F_f1 = f1_score(tffi_y_test, tffi_Randmon_F_pred)\n",
    "tffi_Random_F_accuracy = accuracy_score(tffi_y_test, tffi_Randmon_F_pred)\n",
    "print(\"Measuring Random forest wit TF*IDF :\\n\")\n",
    "print(\"Accuracy:\", tffi_Random_F_accuracy)\n",
    "print(\"Recall:\", tffi_Random_F_recall)\n",
    "print(\"Precision:\", tffi_Random_F_precision)\n",
    "print(\"F1-score:\", tffi_Random_F_f1)\n",
    "\n",
    "bow_Random_F_precision = precision_score(bow_y_test, bow_Randmon_F_pred)\n",
    "bow_Random_F_recall = recall_score(bow_y_test, bow_Randmon_F_pred)\n",
    "bow_Random_F_f1 = f1_score(bow_y_test, bow_Randmon_F_pred)\n",
    "bow_Random_F_accuracy = accuracy_score(bow_y_test, bow_Randmon_F_pred)\n",
    "print(\"\\n\\nMeasuring Random forest wit BOW :\\n\")\n",
    "print(\"Accuracy:\", bow_Random_F_accuracy)\n",
    "print(\"Recall:\", bow_Random_F_recall)\n",
    "print(\"Precision:\", bow_Random_F_precision)\n",
    "print(\"F1-score:\", bow_Random_F_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>SVM with TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9838516746411483"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tffi_SVM=svm.SVC(kernel='rbf',C=10,gamma=0.1)\n",
    "tffi_SVM.fit(tffi_x_train,tffi_y_train)\n",
    "tffi_SVM_pred=tffi_SVM.predict(X=tffi_x_test)\n",
    "tffi_SVM.score(X=tffi_x_test,y=tffi_y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>SVM with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9784688995215312"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_SVM=svm.SVC(kernel='rbf',C=10,gamma=0.1)\n",
    "bow_SVM.fit(bow_x_train,bow_y_train)\n",
    "bow_SVM_pred=bow_SVM.predict(X=bow_x_test)\n",
    "bow_SVM.score(X=bow_x_test,y=bow_y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Measuring SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring SVM wit TF*IDF :\n",
      "\n",
      "Accuracy: 0.9838516746411483\n",
      "Recall: 0.8928571428571429\n",
      "Precision: 0.9852216748768473\n",
      "F1-score: 0.936768149882904\n",
      "\n",
      "\n",
      "Measuring SVM wit BOW :\n",
      "\n",
      "Accuracy: 0.9784688995215312\n",
      "Recall: 0.8392857142857143\n",
      "Precision: 1.0\n",
      "F1-score: 0.9126213592233009\n"
     ]
    }
   ],
   "source": [
    "tffi_SVM_precision = precision_score(tffi_y_test, tffi_SVM_pred)\n",
    "tffi_SVM_recall = recall_score(tffi_y_test, tffi_SVM_pred)\n",
    "tffi_SVM_f1 = f1_score(tffi_y_test, tffi_SVM_pred)\n",
    "tffi_SVM_accuracy = accuracy_score(tffi_y_test, tffi_SVM_pred)\n",
    "print(\"Measuring SVM wit TF*IDF :\\n\")\n",
    "print(\"Accuracy:\", tffi_SVM_accuracy)\n",
    "print(\"Recall:\", tffi_SVM_recall)\n",
    "print(\"Precision:\", tffi_SVM_precision)\n",
    "print(\"F1-score:\", tffi_SVM_f1)\n",
    "\n",
    "bow_SVM_precision = precision_score(bow_y_test, bow_SVM_pred)\n",
    "bow_SVM_recall = recall_score(bow_y_test, bow_SVM_pred)\n",
    "bow_SVM_f1 = f1_score(bow_y_test, bow_SVM_pred)\n",
    "bow_SVM_accuracy = accuracy_score(bow_y_test, bow_SVM_pred)\n",
    "print(\"\\n\\nMeasuring SVM wit BOW :\\n\")\n",
    "print(\"Accuracy:\", bow_SVM_accuracy)\n",
    "print(\"Recall:\", bow_SVM_recall)\n",
    "print(\"Precision:\", bow_SVM_precision)\n",
    "print(\"F1-score:\", bow_SVM_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Learning MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import  keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>split TF*IDF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_tf_x_train_full, mlp_tf_x_test, mlp_tf_y_train_full, mlp_tf_y_test = train_test_split(tffi_tokenized_text.toarray(),text['v1'],random_state=42,shuffle=True,test_size=0.1,stratify=text['v1'])\n",
    "mlp_tf_x_train,mlp_tf_x_valid, mlp_tf_y_train, mlp_tf_y_valid = train_test_split(mlp_tf_x_train_full, mlp_tf_y_train_full,test_size=0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>split BOW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_bow_x_train_full, mlp_bow_x_test, mlp_bow_y_train_full, mlp_bow_y_test = train_test_split(bow_tokenized_text,text['v1'],random_state=42,shuffle=True,test_size=0.1,stratify=text['v1'])\n",
    "mlp_bow_x_train,mlp_bow_x_valid, mlp_bow_y_train, mlp_bow_y_valid = train_test_split(mlp_bow_x_train_full, mlp_bow_y_train_full,test_size=0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>MLP with TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import  keras\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(200, activation='relu', input_shape=(mlp_tf_x_train.shape[1],)))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 7ms/step - loss: 0.3265 - accuracy: 0.9003 - val_loss: 0.1313 - val_accuracy: 0.9582\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0574 - accuracy: 0.9878 - val_loss: 0.0672 - val_accuracy: 0.9761\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.0530 - val_accuracy: 0.9821\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0484 - val_accuracy: 0.9861\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.0457 - val_accuracy: 0.9880\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9880\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9880\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9880\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9880\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 8.4590e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9880\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9785\n",
      "Test loss: 0.08880897611379623\n",
      "Test accuracy: 0.9784946441650391\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(mlp_tf_x_train, mlp_tf_y_train, validation_data=(mlp_tf_x_valid, mlp_tf_y_valid), epochs=10, batch_size=32)\n",
    "# Evaluate the model\n",
    "score1 = model1.evaluate(mlp_tf_x_test, mlp_tf_y_test)\n",
    "print('Test loss:', score1[0])\n",
    "print('Test accuracy:', score1[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>evaluate model on trainig data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/141 [..............................] - ETA: 2s - loss: 9.3194e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step - loss: 7.0392e-04 - accuracy: 1.0000\n",
      "Train Loss: 0.0007039246847853065\n",
      "Train Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the train set\n",
    "train_loss1, train_accuracy1 = model1.evaluate(mlp_tf_x_train, mlp_tf_y_train)\n",
    "print(\"Train Loss:\", train_loss1)\n",
    "print(\"Train Accuracy:\", train_accuracy1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.978494623655914\n",
      "Recall: 0.84\n",
      "Precision: 1.0\n",
      "F1-score: 0.9130434782608696\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob1 = model1.predict(mlp_tf_x_test)\n",
    "\n",
    "# Converting probabilities to class labels based on a threshold \n",
    "y_pred1 = (y_pred_prob1 >= 0.5).astype(int)\n",
    "\n",
    "# Calculating precision, recall, F1-score, and accuracy\n",
    "precision1 = precision_score(mlp_tf_y_test, y_pred1)\n",
    "recall1 = recall_score(mlp_tf_y_test, y_pred1)\n",
    "f11 = f1_score(mlp_tf_y_test, y_pred1)\n",
    "accuracy1 = accuracy_score(mlp_tf_y_test, y_pred1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy1)\n",
    "print(\"Recall:\", recall1)\n",
    "print(\"Precision:\", precision1)\n",
    "print(\"F1-score:\", f11)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MLP with BOW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(200, activation='relu', input_shape=(mlp_bow_x_train.shape[1],)))\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model with SCA optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 0.2377 - accuracy: 0.9528 - val_loss: 0.0561 - val_accuracy: 0.9940\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.0304 - accuracy: 0.9942 - val_loss: 0.0451 - val_accuracy: 0.9880\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.0488 - val_accuracy: 0.9880\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.0515 - val_accuracy: 0.9880\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.0542 - val_accuracy: 0.9880\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0557 - val_accuracy: 0.9880\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0584 - val_accuracy: 0.9880\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0598 - val_accuracy: 0.9880\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 8.8309e-04 - accuracy: 0.9998 - val_loss: 0.0605 - val_accuracy: 0.9880\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 7.0853e-04 - accuracy: 0.9998 - val_loss: 0.0617 - val_accuracy: 0.9880\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9785\n",
      "Test loss: 0.11704761534929276\n",
      "Test accuracy: 0.9784946441650391\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(mlp_bow_x_train, mlp_bow_y_train, validation_data=(mlp_bow_x_valid, mlp_bow_y_valid), epochs=10, batch_size=32)\n",
    "# Evaluate the model\n",
    "score2 = model2.evaluate(mlp_bow_x_test, mlp_bow_y_test)\n",
    "print('Test loss:', score2[0])\n",
    "print('Test accuracy:', score2[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>evaluate model on trainig data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/141 [..............................] - ETA: 2s - loss: 3.9879e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 3ms/step - loss: 5.9515e-04 - accuracy: 0.9998\n",
      "Train Loss: 0.0005951525527052581\n",
      "Train Accuracy: 0.9997783899307251\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the train set\n",
    "train_loss2, train_accuracy2 = model2.evaluate(mlp_bow_x_train, mlp_bow_y_train)\n",
    "print(\"Train Loss:\", train_loss2)\n",
    "print(\"Train Accuracy:\", train_accuracy2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/18 [========================>.....] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.978494623655914\n",
      "Recall: 0.84\n",
      "Precision: 1.0\n",
      "F1-score: 0.9130434782608696\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob2 = model2.predict(mlp_bow_x_test)\n",
    "\n",
    "# Converting probabilities to class labels based on a threshold \n",
    "y_pred2 = (y_pred_prob2 >= 0.5).astype(int)\n",
    "\n",
    "# Calculating precision, recall, F1-score, and accuracy\n",
    "precision2 = precision_score(mlp_bow_y_test, y_pred2)\n",
    "recall2 = recall_score(mlp_bow_y_test, y_pred2)\n",
    "f12 = f1_score(mlp_bow_y_test, y_pred2)\n",
    "accuracy2 = accuracy_score(mlp_bow_y_test, y_pred2)\n",
    "\n",
    "print(\"Accuracy:\", accuracy2)\n",
    "print(\"Recall:\", recall2)\n",
    "print(\"Precision:\", precision2)\n",
    "print(\"F1-score:\", f12)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>MLP with scaled data  TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scailing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "mlp_tf_x_train_scaled = scaler.fit_transform(mlp_tf_x_train)\n",
    "mlp_tf_x_valid_scaled = scaler.transform(mlp_tf_x_valid)\n",
    "mlp_tf_x_test_scaled = scaler.transform(mlp_tf_x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(200, activation='relu', input_shape=(mlp_tf_x_train_scaled.shape[1],)))\n",
    "model3.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 9ms/step - loss: 2.7649 - accuracy: 0.8074 - val_loss: 0.7598 - val_accuracy: 0.9502\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.0871 - accuracy: 0.9887 - val_loss: 0.2226 - val_accuracy: 0.9562\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0070 - accuracy: 0.9973 - val_loss: 0.1848 - val_accuracy: 0.9622\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9681\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 8.7577e-04 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9721\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 4.3794e-04 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9741\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.8591e-04 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9741\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.1099e-04 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9741\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.6446e-04 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9761\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3117e-04 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9761\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9731\n",
      "Test Loss: 0.1654927134513855\n",
      "Test Accuracy: 0.9731183052062988\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(mlp_tf_x_train_scaled, mlp_tf_y_train, validation_data=(mlp_tf_x_valid_scaled, mlp_tf_y_valid), epochs=10, batch_size=32)\n",
    "test_loss3, test_accuracy3 = model3.evaluate(mlp_tf_x_test_scaled, mlp_tf_y_test)\n",
    "print(\"Test Loss:\", test_loss3)\n",
    "print(\"Test Accuracy:\", test_accuracy3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.9731182795698925\n",
      "Recall: 0.8133333333333334\n",
      "Precision: 0.9838709677419355\n",
      "F1-score: 0.8905109489051095\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob3 = model3.predict(mlp_tf_x_test_scaled)\n",
    "\n",
    "# Converting probabilities to class labels based on a threshold \n",
    "y_pred3 = (y_pred_prob3 >= 0.5).astype(int)\n",
    "\n",
    "# Calculating precision, recall, F1-score, and accuracy\n",
    "precision3 = precision_score(mlp_tf_y_test, y_pred3)\n",
    "recall3 = recall_score(mlp_tf_y_test, y_pred3)\n",
    "f13 = f1_score(mlp_tf_y_test, y_pred3)\n",
    "accuracy3 = accuracy_score(mlp_tf_y_test, y_pred3)\n",
    "\n",
    "print(\"Accuracy:\", accuracy3)\n",
    "print(\"Recall:\", recall3)\n",
    "print(\"Precision:\", precision3)\n",
    "print(\"F1-score:\", f13)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feature Selection with SCA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sca import SCAFUN    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>We have to scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2=StandardScaler()\n",
    "scaled_data=scaler2.fit_transform(tffi_tokenized_text.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8820)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_obj_data=scaled_data.astype(float)\n",
    "scaled_obj_label=text['v1'].astype(float)\n",
    "scaled_obj_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>First extract TFIDF feature vectors with SCA on scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_train_SCA, scaled_x_valid_SCA, scaled_y_train_SCA, scaled_y_valid_SCA = train_test_split(scaled_obj_data, scaled_obj_label, test_size=0.2, stratify=scaled_obj_label,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = {'x_train':scaled_x_train_SCA, 'y_train':scaled_y_train_SCA, 'x_valid':scaled_x_valid_SCA, 'y_valid':scaled_y_valid_SCA}\n",
    "T    = 5   # maximum number of iterations\n",
    "opts = {'fold':fold, 'T':T,'alpha':0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 3ms/step - loss: 0.6953\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.4595\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0996\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.1472\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0830\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.7940\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.1848\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0477\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0084\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0609\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.9274\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 4ms/step - loss: 0.4794\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.1533\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0446\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0392\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.7051\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 4ms/step - loss: 0.4028\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.2158\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.1208\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0605\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.7100\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.2421\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0286\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0184\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 4ms/step - loss: 0.0245\n",
      "35/35 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "SCA_output1 = SCAFUN(scaled_obj_data, scaled_obj_label, opts)\n",
    "sf1   = SCA_output1['selected_features']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Size of selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4411"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf1.size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>So  8820-4391=4429 features were omitted by applying  SCA "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>splite extracted scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca_x_train,mlp_sca_x_test,sca_y_train,mlp_sca_y_test=train_test_split(scaled_obj_data[:,sf1],scaled_obj_label,test_size=0.3,stratify=scaled_obj_label,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_sca_x_train,mlp_sca_x_valid, mlp_sca_y_train, mlp_sca_y_valid = train_test_split(sca_x_train, sca_y_train,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Now extract BOW feature vectors with SCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8820)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_obj_data=bow_tokenized_text.astype(float)\n",
    "bow_obj_label=text['v1'].astype(float)\n",
    "bow_obj_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_x_train, bow_x_valid, bow_y_train, bow_y_valid = train_test_split(bow_obj_data, bow_obj_label, test_size=0.2, stratify=bow_obj_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = {'x_train':bow_x_train, 'y_train':bow_y_train, 'x_valid':bow_x_valid, 'y_valid':bow_y_valid}\n",
    "T    = 5   # maximum number of iterations\n",
    "opts = {'fold':fold, 'T':T,'alpha':0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 3ms/step - loss: 0.1371\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0250\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0127\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0094\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0082\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.1427\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0250\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0124\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0100\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0086\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.1371\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0265\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0124\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0106\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0082\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.1383\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0233\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0107\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0071\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0071\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.1357\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0244\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0109\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0075\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0069\n",
      "35/35 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "SCA_output2 = SCAFUN(bow_obj_data, bow_obj_label, opts)\n",
    "sf2   = SCA_output2['selected_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4419,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf2.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>So  8820-4462=4358 features were omitted by applying  SCA "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>load extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca_x_bow_train,mlp_sca_x_bow_test,sca_y_bow_train,mlp_sca_y_bow_test=train_test_split(bow_obj_data[:,sf2],bow_obj_label,test_size=0.3,stratify=bow_obj_label,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_sca_bow_x_train,mlp_sca_bow_x_valid, mlp_sca_bow_y_train, mlp_sca_bow_y_valid = train_test_split(sca_x_bow_train, sca_y_bow_train,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KNN with SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868421052631579"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCA_tffi_knn=KNeighborsClassifier(n_neighbors=13)\n",
    "SCA_tffi_knn.fit(sca_x_train,sca_y_train)\n",
    "SCA_knn_tffi_pred=SCA_tffi_knn.predict(X=mlp_sca_x_test)\n",
    "SCA_tffi_knn.score(X=mlp_sca_x_test,y=mlp_sca_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8845693779904307"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCA_bow_knn=KNeighborsClassifier(n_neighbors=13)\n",
    "SCA_bow_knn.fit(X=sca_x_bow_train,y=sca_y_bow_train)\n",
    "SCA_knn_bow_pred=SCA_bow_knn.predict(X=mlp_sca_x_bow_test)\n",
    "SCA_bow_knn.score(X=mlp_sca_x_bow_test,y=mlp_sca_y_bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring knn wit TF*IDF SCA:\n",
      "\n",
      "Accuracy: 0.868421052631579\n",
      "Recall: 0.017857142857142856\n",
      "Precision: 1.0\n",
      "F1-score: 0.03508771929824561\n",
      "\n",
      "\n",
      "Measuring knn wit BOW SCA :\n",
      "\n",
      "Accuracy: 0.8845693779904307\n",
      "Recall: 0.13839285714285715\n",
      "Precision: 1.0\n",
      "F1-score: 0.24313725490196078\n"
     ]
    }
   ],
   "source": [
    "SCA_knn_tffi_precision = precision_score(mlp_sca_y_test, SCA_knn_tffi_pred)\n",
    "SCA_knn_tffi_recall = recall_score(mlp_sca_y_test, SCA_knn_tffi_pred)\n",
    "SCA_knn_tffi_f1 = f1_score(mlp_sca_y_test, SCA_knn_tffi_pred)\n",
    "SCA_knn_tffi_accuracy = accuracy_score(mlp_sca_y_test, SCA_knn_tffi_pred)\n",
    "print(\"Measuring knn wit TF*IDF SCA:\\n\")\n",
    "print(\"Accuracy:\", SCA_knn_tffi_accuracy)\n",
    "print(\"Recall:\", SCA_knn_tffi_recall)\n",
    "print(\"Precision:\", SCA_knn_tffi_precision)\n",
    "print(\"F1-score:\", SCA_knn_tffi_f1)\n",
    "\n",
    "SCA_knn_bow_precision = precision_score(mlp_sca_y_bow_test, SCA_knn_bow_pred)\n",
    "SCA_knn_bow_recall = recall_score(mlp_sca_y_bow_test, SCA_knn_bow_pred)\n",
    "SCA_knn_bow_f1 = f1_score(mlp_sca_y_bow_test, SCA_knn_bow_pred)\n",
    "SCA_knn_bow_accuracy = accuracy_score(mlp_sca_y_bow_test, SCA_knn_bow_pred)\n",
    "print(\"\\n\\nMeasuring knn wit BOW SCA :\\n\")\n",
    "print(\"Accuracy:\", SCA_knn_bow_accuracy)\n",
    "print(\"Recall:\", SCA_knn_bow_recall)\n",
    "print(\"Precision:\", SCA_knn_bow_precision)\n",
    "print(\"F1-score:\", SCA_knn_bow_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random forest with SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9665071770334929"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCA_tffi_Random_F=RandomForestClassifier(n_estimators=31,criterion='gini')\n",
    "SCA_tffi_Random_F.fit(sca_x_train,sca_y_train)\n",
    "SCA_tffi_Randmon_F_pred=SCA_tffi_Random_F.predict(X=mlp_sca_x_test)\n",
    "SCA_tffi_Random_F.score(X=mlp_sca_x_test,y=mlp_sca_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9683014354066986"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCA_bow_Random_F=RandomForestClassifier(n_estimators=31,criterion='gini')\n",
    "SCA_bow_Random_F.fit(sca_x_bow_train,sca_y_bow_train)\n",
    "SCA_bow_Randmon_F_pred=SCA_bow_Random_F.predict(X=mlp_sca_x_bow_test)\n",
    "SCA_bow_Random_F.score(X=mlp_sca_x_bow_test,y=mlp_sca_y_bow_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>measuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring Random forest wit TF*IDF :\n",
      "\n",
      "Accuracy: 0.9665071770334929\n",
      "Recall: 0.7723214285714286\n",
      "Precision: 0.9719101123595506\n",
      "F1-score: 0.8606965174129354\n",
      "\n",
      "\n",
      "Measuring Random forest wit BOW :\n",
      "\n",
      "Accuracy: 0.9683014354066986\n",
      "Recall: 0.7946428571428571\n",
      "Precision: 0.9621621621621622\n",
      "F1-score: 0.8704156479217603\n"
     ]
    }
   ],
   "source": [
    "SCA_tffi_Random_F_precision = precision_score(mlp_sca_y_test, SCA_tffi_Randmon_F_pred)\n",
    "SCA_tffi_Random_F_recall = recall_score(mlp_sca_y_test, SCA_tffi_Randmon_F_pred)\n",
    "SCA_tffi_Random_F_f1 = f1_score(mlp_sca_y_test, SCA_tffi_Randmon_F_pred)\n",
    "SCA_tffi_Random_F_accuracy = accuracy_score(mlp_sca_y_test, SCA_tffi_Randmon_F_pred)\n",
    "print(\"Measuring Random forest wit TF*IDF :\\n\")\n",
    "print(\"Accuracy:\", SCA_tffi_Random_F_accuracy)\n",
    "print(\"Recall:\", SCA_tffi_Random_F_recall)\n",
    "print(\"Precision:\", SCA_tffi_Random_F_precision)\n",
    "print(\"F1-score:\", SCA_tffi_Random_F_f1)\n",
    "\n",
    "SCA_bow_Random_F_precision = precision_score(mlp_sca_y_bow_test, SCA_bow_Randmon_F_pred)\n",
    "SCA_bow_Random_F_recall = recall_score(mlp_sca_y_bow_test, SCA_bow_Randmon_F_pred)\n",
    "SCA_bow_Random_F_f1 = f1_score(mlp_sca_y_bow_test, SCA_bow_Randmon_F_pred)\n",
    "SCA_bow_Random_F_accuracy = accuracy_score(mlp_sca_y_bow_test, SCA_bow_Randmon_F_pred)\n",
    "print(\"\\n\\nMeasuring Random forest wit BOW :\\n\")\n",
    "print(\"Accuracy:\", SCA_bow_Random_F_accuracy)\n",
    "print(\"Recall:\", SCA_bow_Random_F_recall)\n",
    "print(\"Precision:\", SCA_bow_Random_F_precision)\n",
    "print(\"F1-score:\", SCA_bow_Random_F_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SCA SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8983253588516746"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCA_tffi_SVM=svm.SVC(kernel='rbf',C=10,gamma=0.1)\n",
    "SCA_tffi_SVM.fit(sca_x_train,sca_y_train)\n",
    "SCA_tffi_SVM_pred=SCA_tffi_SVM.predict(X=mlp_sca_x_test)\n",
    "SCA_tffi_SVM.score(X=mlp_sca_x_test,y=mlp_sca_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9706937799043063"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCA_bow_SVM=svm.SVC(kernel='rbf',C=10,gamma=0.1)\n",
    "SCA_bow_SVM.fit(sca_x_bow_train,sca_y_bow_train)\n",
    "SCA_bow_SVM_pred=SCA_bow_SVM.predict(X=mlp_sca_x_bow_test)\n",
    "SCA_bow_SVM.score(X=mlp_sca_x_bow_test,y=mlp_sca_y_bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring SVM wit TF*IDF :\n",
      "\n",
      "Accuracy: 0.8983253588516746\n",
      "Recall: 0.24553571428571427\n",
      "Precision: 0.9821428571428571\n",
      "F1-score: 0.39285714285714285\n",
      "\n",
      "\n",
      "Measuring SVM wit BOW :\n",
      "\n",
      "Accuracy: 0.9706937799043063\n",
      "Recall: 0.8169642857142857\n",
      "Precision: 0.9581151832460733\n",
      "F1-score: 0.8819277108433735\n"
     ]
    }
   ],
   "source": [
    "SCA_tffi_SVM_precision = precision_score(mlp_sca_y_test, SCA_tffi_SVM_pred)\n",
    "SCA_tffi_SVM_recall = recall_score(mlp_sca_y_test, SCA_tffi_SVM_pred)\n",
    "SCA_tffi_SVM_f1 = f1_score(mlp_sca_y_test, SCA_tffi_SVM_pred)\n",
    "SCA_tffi_SVM_accuracy = accuracy_score(mlp_sca_y_test, SCA_tffi_SVM_pred)\n",
    "print(\"Measuring SVM wit TF*IDF :\\n\")\n",
    "print(\"Accuracy:\", SCA_tffi_SVM_accuracy)\n",
    "print(\"Recall:\", SCA_tffi_SVM_recall)\n",
    "print(\"Precision:\", SCA_tffi_SVM_precision)\n",
    "print(\"F1-score:\", SCA_tffi_SVM_f1)\n",
    "\n",
    "SCA_bow_SVM_precision = precision_score(mlp_sca_y_bow_test, SCA_bow_SVM_pred)\n",
    "SCA_bow_SVM_recall = recall_score(mlp_sca_y_bow_test, SCA_bow_SVM_pred)\n",
    "SCA_bow_SVM_f1 = f1_score(mlp_sca_y_bow_test, SCA_bow_SVM_pred)\n",
    "SCA_bow_SVM_accuracy = accuracy_score(mlp_sca_y_bow_test, SCA_bow_SVM_pred)\n",
    "print(\"\\n\\nMeasuring SVM wit BOW :\\n\")\n",
    "print(\"Accuracy:\", SCA_bow_SVM_accuracy)\n",
    "print(\"Recall:\", SCA_bow_SVM_recall)\n",
    "print(\"Precision:\", SCA_bow_SVM_precision)\n",
    "print(\"F1-score:\", SCA_bow_SVM_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Make mlp with SCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 2.6645 - accuracy: 0.7577 - val_loss: 0.9846 - val_accuracy: 0.8474\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.1734 - accuracy: 0.9612 - val_loss: 0.2242 - val_accuracy: 0.9372\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9875 - val_loss: 0.1774 - val_accuracy: 0.9513\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.1843 - val_accuracy: 0.9551\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.1945 - val_accuracy: 0.9526\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.2077 - val_accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9990 - val_loss: 0.2204 - val_accuracy: 0.9513\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9994 - val_loss: 0.2383 - val_accuracy: 0.9449\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.2692 - val_accuracy: 0.9436\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.2616 - val_accuracy: 0.9436\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.9444\n",
      "Test loss: 0.2531498074531555\n",
      "Test accuracy: 0.9443780183792114\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(200, activation='relu', input_shape=(mlp_sca_x_train.shape[1],)))\n",
    "model5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model \n",
    "model5.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Training the model\n",
    "history5 = model5.fit(mlp_sca_x_train, mlp_sca_y_train, validation_data=(mlp_sca_x_valid, mlp_sca_y_valid), epochs=10, batch_size=32)\n",
    "# Evaluate the model\n",
    "score5 = model5.evaluate(mlp_sca_x_test, mlp_sca_y_test)\n",
    "print('Test loss:', score5[0])\n",
    "print('Test accuracy:', score5[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>evalute model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/53 [..............................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.944377990430622\n",
      "Recall: 0.8705357142857143\n",
      "Precision: 0.752895752895753\n",
      "F1-score: 0.8074534161490683\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob5 = model5.predict(mlp_sca_x_test)\n",
    "\n",
    "# Converting probabilities to class labels based on a threshold (e.g., 0.5)\n",
    "y_pred5 = (y_pred_prob5 >= 0.5).astype(int)\n",
    "\n",
    "# Calculating precision, recall, F1-score, and accuracy\n",
    "precision5 = precision_score(mlp_sca_y_test, y_pred5)\n",
    "recall5 = recall_score(mlp_sca_y_test, y_pred5)\n",
    "f15 = f1_score(mlp_sca_y_test, y_pred5)\n",
    "accuracy5 = accuracy_score(mlp_sca_y_test, y_pred5)\n",
    "\n",
    "print(\"Accuracy:\", accuracy5)\n",
    "print(\"Recall:\", recall5)\n",
    "print(\"Precision:\", precision5)\n",
    "print(\"F1-score:\", f15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>make mlp _ SCA on BOW data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.3751 - accuracy: 0.9122 - val_loss: 0.1794 - val_accuracy: 0.9551\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9769 - val_loss: 0.1145 - val_accuracy: 0.9667\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9878 - val_loss: 0.1072 - val_accuracy: 0.9692\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 0.9936 - val_loss: 0.1076 - val_accuracy: 0.9705\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9955 - val_loss: 0.1142 - val_accuracy: 0.9692\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9971 - val_loss: 0.1174 - val_accuracy: 0.9679\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9974 - val_loss: 0.1213 - val_accuracy: 0.9679\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.1265 - val_accuracy: 0.9692\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.1307 - val_accuracy: 0.9679\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.1330 - val_accuracy: 0.9679\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9779\n",
      "Test loss: 0.1052713543176651\n",
      "Test accuracy: 0.9778708219528198\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(200, activation='relu', input_shape=(mlp_sca_bow_x_train.shape[1],)))\n",
    "model6.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with SCA optimizer\n",
    "model6.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Training the model\n",
    "history6 = model6.fit(mlp_sca_bow_x_train, mlp_sca_bow_y_train, validation_data=(mlp_sca_bow_x_valid, mlp_sca_bow_y_valid), epochs=10, batch_size=32)\n",
    "# Evaluate the model\n",
    "score6 = model6.evaluate(mlp_sca_x_bow_test, mlp_sca_y_bow_test)\n",
    "print('Test loss:', score6[0])\n",
    "print('Test accuracy:', score6[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9987\n",
      "Train Loss: 0.008931545540690422\n",
      "Train Accuracy: 0.9987179636955261\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loss6, train_accuracy6 = model6.evaluate(mlp_sca_bow_x_train, mlp_sca_bow_y_train)\n",
    "print(\"Train Loss:\", train_loss6)\n",
    "print(\"Train Accuracy:\", train_accuracy6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.9778708133971292\n",
      "Recall: 0.8526785714285714\n",
      "Precision: 0.9794871794871794\n",
      "F1-score: 0.9116945107398569\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob6 = model6.predict(mlp_sca_x_bow_test)\n",
    "\n",
    "# Converting probabilities to class labels based on a threshold (e.g., 0.5)\n",
    "y_pred6 = (y_pred_prob6 >= 0.5).astype(int)\n",
    "\n",
    "# Calculating precision, recall, F1-score, and accuracy\n",
    "precision6 = precision_score(mlp_sca_y_bow_test, y_pred6)\n",
    "recall6 = recall_score(mlp_sca_y_bow_test, y_pred6)\n",
    "f16 = f1_score(mlp_sca_y_bow_test, y_pred6)\n",
    "accuracy6 = accuracy_score(mlp_sca_y_bow_test, y_pred6)\n",
    "\n",
    "print(\"Accuracy:\", accuracy6)\n",
    "print(\"Recall:\", recall6)\n",
    "print(\"Precision:\", precision6)\n",
    "print(\"F1-score:\", f16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>make result Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy      BOW</th>\n",
       "      <th>Accuracy   TF-IDF</th>\n",
       "      <th>Precision     BOW</th>\n",
       "      <th>Precision  TF-IDF</th>\n",
       "      <th>Recall        BOW</th>\n",
       "      <th>Recall     TF-IDF</th>\n",
       "      <th>F-measure     BOW</th>\n",
       "      <th>F-measure  TF-IDF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>97.849462</td>\n",
       "      <td>97.849462</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>91.304348</td>\n",
       "      <td>91.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-scaled</th>\n",
       "      <td>----------</td>\n",
       "      <td>97.311828</td>\n",
       "      <td>----------</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>----------</td>\n",
       "      <td>98.387097</td>\n",
       "      <td>----------</td>\n",
       "      <td>89.051095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-SCA</th>\n",
       "      <td>97.787081</td>\n",
       "      <td>94.437799</td>\n",
       "      <td>85.267857</td>\n",
       "      <td>87.053571</td>\n",
       "      <td>97.948718</td>\n",
       "      <td>75.289575</td>\n",
       "      <td>91.169451</td>\n",
       "      <td>80.745342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>87.739234</td>\n",
       "      <td>94.796651</td>\n",
       "      <td>8.482143</td>\n",
       "      <td>61.160714</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>15.63786</td>\n",
       "      <td>75.900277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN-SCA</th>\n",
       "      <td>88.456938</td>\n",
       "      <td>86.842105</td>\n",
       "      <td>13.839286</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>24.313725</td>\n",
       "      <td>3.508772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>97.84689</td>\n",
       "      <td>98.385167</td>\n",
       "      <td>83.928571</td>\n",
       "      <td>89.285714</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.522167</td>\n",
       "      <td>91.262136</td>\n",
       "      <td>93.676815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM-SCA</th>\n",
       "      <td>97.069378</td>\n",
       "      <td>89.832536</td>\n",
       "      <td>81.696429</td>\n",
       "      <td>24.553571</td>\n",
       "      <td>95.811518</td>\n",
       "      <td>98.214286</td>\n",
       "      <td>88.192771</td>\n",
       "      <td>39.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R.forest</th>\n",
       "      <td>97.547847</td>\n",
       "      <td>97.368421</td>\n",
       "      <td>81.696429</td>\n",
       "      <td>81.696429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.387097</td>\n",
       "      <td>89.92629</td>\n",
       "      <td>89.268293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R.forest-SCA</th>\n",
       "      <td>96.830144</td>\n",
       "      <td>96.650718</td>\n",
       "      <td>79.464286</td>\n",
       "      <td>77.232143</td>\n",
       "      <td>96.216216</td>\n",
       "      <td>97.191011</td>\n",
       "      <td>87.041565</td>\n",
       "      <td>86.069652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy      BOW  Accuracy   TF-IDF Precision     BOW  \\\n",
       "Algorithm                                                             \n",
       "MLP                  97.849462          97.849462              84.0   \n",
       "MLP-scaled          ----------          97.311828        ----------   \n",
       "MLP-SCA              97.787081          94.437799         85.267857   \n",
       "KNN                  87.739234          94.796651          8.482143   \n",
       "KNN-SCA              88.456938          86.842105         13.839286   \n",
       "SVM                   97.84689          98.385167         83.928571   \n",
       "SVM-SCA              97.069378          89.832536         81.696429   \n",
       "R.forest             97.547847          97.368421         81.696429   \n",
       "R.forest-SCA         96.830144          96.650718         79.464286   \n",
       "\n",
       "              Precision  TF-IDF Recall        BOW  Recall     TF-IDF  \\\n",
       "Algorithm                                                              \n",
       "MLP                   84.000000             100.0         100.000000   \n",
       "MLP-scaled            81.333333        ----------          98.387097   \n",
       "MLP-SCA               87.053571         97.948718          75.289575   \n",
       "KNN                   61.160714             100.0         100.000000   \n",
       "KNN-SCA                1.785714             100.0         100.000000   \n",
       "SVM                   89.285714             100.0          98.522167   \n",
       "SVM-SCA               24.553571         95.811518          98.214286   \n",
       "R.forest              81.696429             100.0          98.387097   \n",
       "R.forest-SCA          77.232143         96.216216          97.191011   \n",
       "\n",
       "             F-measure     BOW  F-measure  TF-IDF  \n",
       "Algorithm                                          \n",
       "MLP                  91.304348          91.304348  \n",
       "MLP-scaled          ----------          89.051095  \n",
       "MLP-SCA              91.169451          80.745342  \n",
       "KNN                   15.63786          75.900277  \n",
       "KNN-SCA              24.313725           3.508772  \n",
       "SVM                  91.262136          93.676815  \n",
       "SVM-SCA              88.192771          39.285714  \n",
       "R.forest              89.92629          89.268293  \n",
       "R.forest-SCA         87.041565          86.069652  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mlp_12 = {'Algorithm': 'MLP', 'Accuracy_BOW': accuracy2*100 ,'Accuracy_TF-IDF':accuracy1*100 , 'Recall_BOW': recall2*100, 'Recall_TF-IDF': recall1*100,'Precision_BOW':precision2*100  ,'Precision_TF-IDF':precision1*100 ,'F-measure_BOW':f12*100,'F-measure_TF-IDF':f12*100}\n",
    "results_mlp3 = {'Algorithm': 'MLP-scaled', 'Accuracy_BOW': '----------' ,'Accuracy_TF-IDF':accuracy3*100 , 'Recall_BOW': '----------', 'Recall_TF-IDF': recall3*100,'Precision_BOW':'----------'  ,'Precision_TF-IDF':precision3*100 ,'F-measure_BOW':'----------','F-measure_TF-IDF':f13*100}\n",
    "results_mlp_56 = {'Algorithm': 'MLP-SCA', 'Accuracy_BOW': accuracy6*100 ,'Accuracy_TF-IDF':accuracy5*100 , 'Recall_BOW': recall6*100, 'Recall_TF-IDF': recall5*100,'Precision_BOW':precision6*100  ,'Precision_TF-IDF':precision5*100 ,'F-measure_BOW':f16*100,'F-measure_TF-IDF':f15*100}\n",
    "results_knn = {'Algorithm': 'KNN', 'Accuracy_BOW': knn_bow_accuracy*100 ,'Accuracy_TF-IDF':knn_tffi_accuracy*100 , 'Recall_BOW': knn_bow_recall*100, 'Recall_TF-IDF': knn_tffi_recall*100,'Precision_BOW':knn_bow_precision*100  ,'Precision_TF-IDF':knn_tffi_precision*100 ,'F-measure_BOW':knn_bow_f1*100,'F-measure_TF-IDF':knn_tffi_f1*100}\n",
    "results_svm = {'Algorithm': 'SVM', 'Accuracy_BOW': bow_SVM_accuracy*100 ,'Accuracy_TF-IDF':tffi_SVM_accuracy*100 , 'Recall_BOW': bow_SVM_recall*100, 'Recall_TF-IDF': tffi_SVM_recall*100,'Precision_BOW':bow_SVM_precision*100  ,'Precision_TF-IDF':tffi_SVM_precision*100 ,'F-measure_BOW':bow_SVM_f1*100,'F-measure_TF-IDF':tffi_SVM_f1*100}\n",
    "results_rf = {'Algorithm': 'R.forest', 'Accuracy_BOW': bow_Random_F_accuracy*100 ,'Accuracy_TF-IDF':tffi_Random_F_accuracy*100 , 'Recall_BOW': bow_Random_F_recall*100, 'Recall_TF-IDF': tffi_Random_F_recall*100,'Precision_BOW':bow_Random_F_precision*100  ,'Precision_TF-IDF':tffi_Random_F_precision*100 ,'F-measure_BOW':bow_Random_F_f1*100,'F-measure_TF-IDF':tffi_Random_F_f1*100}\n",
    "\n",
    "\n",
    "\n",
    "results_SCA_knn = {'Algorithm': 'KNN-SCA', 'Accuracy_BOW': SCA_knn_bow_accuracy*100 ,'Accuracy_TF-IDF':SCA_knn_tffi_accuracy*100 , 'Recall_BOW': SCA_knn_bow_recall*100, 'Recall_TF-IDF': SCA_knn_tffi_recall*100,'Precision_BOW':SCA_knn_bow_precision*100  ,'Precision_TF-IDF':SCA_knn_tffi_precision*100 ,'F-measure_BOW':SCA_knn_bow_f1*100,'F-measure_TF-IDF':SCA_knn_tffi_f1*100}\n",
    "results_SCA_svm = {'Algorithm': 'SVM-SCA', 'Accuracy_BOW': SCA_bow_SVM_accuracy*100 ,'Accuracy_TF-IDF':SCA_tffi_SVM_accuracy*100 , 'Recall_BOW': SCA_bow_SVM_recall*100, 'Recall_TF-IDF': SCA_tffi_SVM_recall*100,'Precision_BOW':SCA_bow_SVM_precision*100  ,'Precision_TF-IDF':SCA_tffi_SVM_precision*100 ,'F-measure_BOW':SCA_bow_SVM_f1*100,'F-measure_TF-IDF':SCA_tffi_SVM_f1*100}\n",
    "results_SCA_rf = {'Algorithm': 'R.forest-SCA', 'Accuracy_BOW': SCA_bow_Random_F_accuracy*100 ,'Accuracy_TF-IDF':SCA_tffi_Random_F_accuracy*100 , 'Recall_BOW': SCA_bow_Random_F_recall*100, 'Recall_TF-IDF': SCA_tffi_Random_F_recall*100,'Precision_BOW':SCA_bow_Random_F_precision*100  ,'Precision_TF-IDF':SCA_tffi_Random_F_precision*100 ,'F-measure_BOW':SCA_bow_Random_F_f1*100,'F-measure_TF-IDF':SCA_tffi_Random_F_f1*100}\n",
    "df = pd.DataFrame([results_mlp_12, results_mlp3,results_mlp_56,results_knn,results_SCA_knn,results_svm,results_SCA_svm,results_rf,results_SCA_rf])\n",
    "df.set_index('Algorithm', inplace=True)\n",
    "columns = pd.MultiIndex.from_tuples([\n",
    "    ('Accuracy', 'BOW'), ('Accuracy', 'TF-IDF'),\n",
    "    ('Precision', 'BOW'), ('Precision', 'TF-IDF'),\n",
    "    ('Recall', 'BOW'), ('Recall', 'TF-IDF'),\n",
    "    ('F-measure', 'BOW'), ('F-measure', 'TF-IDF')\n",
    "])\n",
    "\n",
    "df.columns = columns\n",
    "\n",
    "# Define column spacing\n",
    "col_width = max(len(name) for name in df.columns.get_level_values(0))\n",
    "level_width = max(len(str(level)) for level in df.columns.get_level_values(1))\n",
    "spacing = 2  # Number of extra spaces between columns\n",
    "\n",
    "# Function to format column headers with adjusted spacing\n",
    "def format_columns(columns):\n",
    "    return [f\"{col:{col_width}s}{level:>{level_width + spacing}s}\" for col, level in columns]\n",
    "\n",
    "# Format columns with adjusted spacing\n",
    "df.columns = format_columns(df.columns)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Save  result table as chart.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([results_mlp_12, results_mlp3,results_mlp_56,results_knn,results_SCA_knn,results_svm,results_SCA_svm,results_rf,results_SCA_rf])\n",
    "df.set_index('Algorithm', inplace=True)\n",
    "df.to_csv('chart_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
